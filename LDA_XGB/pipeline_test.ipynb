{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "255ebe64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_predict\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "regions = 'dkt95'\n",
    "# regions = 'dkt62'\n",
    "\n",
    "\n",
    "## WSEV data prep\n",
    "new_wsev = pd.read_csv(\"C:/Users/BREIN/Desktop/copathology_visualization_temp/data/260108_wsev_final_df.csv\")\n",
    "hc_df = new_wsev[new_wsev['DX'] == 'HC']\n",
    "\n",
    "df_wsev = pd.read_csv('C:/Users/BREIN/Desktop/copathology_visualization_temp/data/wsev_old_100_data.csv')\n",
    "df_wsev = df_wsev.dropna()\n",
    "print(df_wsev['DX'].value_counts())\n",
    "\n",
    "if regions == 'dkt62':\n",
    "    region_cols = df_wsev.loc[:, 'VA/1002':'VA/2035'].columns\n",
    "    X_hc = hc_df[hc_df.loc[:,'ctx_lh_caudalanteriorcingulate':'ctx_rh_insula'].columns].values.astype(float)\n",
    "    print(f\"HC: {X_hc.shape[0]} subjects\")\n",
    "    hc_mean = X_hc.mean(axis=0, keepdims=True)\n",
    "    hc_std  = X_hc.std(axis=0, keepdims=True) + 1e-8  # avoid divide-by-zero\n",
    "\n",
    "elif regions == 'dkt95':\n",
    "    region_cols = df_wsev.loc[:, 'VA/2':'VA/2035'].columns\n",
    "    X_hc = hc_df[hc_df.loc[:,'Left_Cerebral_White_Matter':'ctx_rh_insula'].columns].values.astype(float)\n",
    "    print(f\"HC: {X_hc.shape[0]} subjects\")\n",
    "    hc_mean = X_hc.mean(axis=0, keepdims=True)\n",
    "    hc_std  = X_hc.std(axis=0, keepdims=True) + 1e-8  # avoid divide-by-zero\n",
    "\n",
    "X_wsev = df_wsev[region_cols].values.astype(float)\n",
    "print(f\"Patients: {X_wsev.shape[0]} subjects\")\n",
    "\n",
    "Z_wsev = (X_wsev - hc_mean) / hc_std\n",
    "X_wsev = np.maximum(-Z_wsev, 0.0)\n",
    "X_wsev[X_wsev < 0] = 0.0\n",
    "\n",
    "## SMC data prep\n",
    "df_smc = pd.read_csv('C:/Users/BREIN/Desktop/copathology_visualization_temp/data/SMC_AD_FTD_VA_final.csv')\n",
    "df_nc = df_smc[df_smc['DX'] == 'NC']\n",
    "df_smc_pat = df_smc[df_smc['DX'] != 'NC']\n",
    "print(df_smc_pat['DX'].value_counts())\n",
    "\n",
    "if regions == 'dkt62':\n",
    "    region_cols = df_smc_pat.loc[:, 'VA/1002':'VA/2035'].columns\n",
    "    X_nc = df_nc[df_nc.loc[:,'VA/1002':'VA/2035'].columns].values.astype(float)\n",
    "    print(f\"NC: {X_nc.shape[0]} subjects\")\n",
    "    nc_mean = X_nc.mean(axis=0, keepdims=True)\n",
    "    nc_std  = X_nc.std(axis=0, keepdims=True) + 1e-8  # avoid divide-by-zero\n",
    "\n",
    "elif regions == 'dkt95':\n",
    "    region_cols = df_smc_pat.loc[:, 'VA/2':'VA/2035'].columns\n",
    "    X_nc = df_nc[df_nc.loc[:,'VA/2':'VA/2035'].columns].values.astype(float)\n",
    "    print(f\"NC: {X_nc.shape[0]} subjects\")\n",
    "    nc_mean = X_nc.mean(axis=0, keepdims=True)\n",
    "    nc_std  = X_nc.std(axis=0, keepdims=True) + 1e-8  # avoid divide-by-zero\n",
    "\n",
    "X_smc = df_smc_pat[region_cols].values.astype(float)\n",
    "print(f\"Patients: {X_smc.shape[0]} subjects\")\n",
    "\n",
    "Z_smc = (X_smc - nc_mean) / nc_std\n",
    "X_smc = np.maximum(-Z_smc, 0.0)\n",
    "X_smc[X_smc < 0] = 0.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c832b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## combine cohorts\n",
    "# -------------------------------\n",
    "# WSEV cohort\n",
    "# -------------------------------\n",
    "df_wsev_x = pd.DataFrame(\n",
    "    X_wsev,\n",
    "    columns=region_cols\n",
    ")\n",
    "\n",
    "df_wsev_x.insert(0, \"SUBJ_ID\", df_wsev[\"PTID\"].values)\n",
    "df_wsev_x.insert(1, \"DX\", df_wsev[\"DX\"].values)\n",
    "\n",
    "\n",
    "# -------------------------------\n",
    "# SMC cohort\n",
    "# -------------------------------\n",
    "df_smc_x = pd.DataFrame(\n",
    "    X_smc,\n",
    "    columns=region_cols\n",
    ")\n",
    "\n",
    "df_smc_x.insert(0, \"SUBJ_ID\", df_smc_pat[\"PTID\"].values)\n",
    "df_smc_x.insert(1, \"DX\", df_smc_pat[\"DX\"].values)\n",
    "\n",
    "\n",
    "# df_smc_x = downsample_to_n_per_class(df_smc)\n",
    "\n",
    "# -------------------------------\n",
    "# Safety check: align ROI columns\n",
    "# -------------------------------\n",
    "meta_cols = [\"SUBJ_ID\", \"DX\"]\n",
    "roi_cols = list(region_cols)  # already aligned by construction\n",
    "\n",
    "df_wsev_x = df_wsev_x[meta_cols + roi_cols]\n",
    "# df_smc_x  = df_smc_x[['PTID', 'DX'] + roi_cols]\n",
    "df_smc_x  = df_smc_x[meta_cols + roi_cols]\n",
    "\n",
    "\n",
    "# -------------------------------\n",
    "# Concatenate cohorts\n",
    "# -------------------------------\n",
    "df_combined = pd.concat(\n",
    "    [df_wsev_x, df_smc_x],\n",
    "    axis=0,\n",
    "    ignore_index=True\n",
    ")\n",
    "\n",
    "df_combined = df_combined.dropna()\n",
    "print(\"Combined shape:\", df_combined.shape)\n",
    "# print(df_combined.head())\n",
    "print(df_combined['DX'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f337420",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from data_processor import *\n",
    "from lda_model import LDATopicModel\n",
    "from classifier import TopicClassifier\n",
    "from visualizer import *\n",
    "from brain_visualizer import *\n",
    "\n",
    "N_TOPICS = 18 ###\n",
    "inp_df = pd.read_csv('C:/Users/BREIN/Desktop/copathology_visualization_temp/data/260120_wsev_smc_combined_zscores.csv')\n",
    "\n",
    "N = 25\n",
    "dx_col = \"DX\"\n",
    "balanced_parts = []\n",
    "\n",
    "for dx, g in inp_df.groupby(dx_col):\n",
    "    # if dx == 'AD':\n",
    "    #     N=50\n",
    "    # else: \n",
    "    #     N=25\n",
    "    if len(g) > N:\n",
    "        g = g.sample(n=N, replace=False, random_state=42)\n",
    "    balanced_parts.append(g)\n",
    "\n",
    "balanced_df = pd.concat(balanced_parts).reset_index(drop=True)\n",
    "print(balanced_df[dx_col].value_counts())\n",
    "\n",
    "inp_df = balanced_df\n",
    "\n",
    "# Define your region columns (adjust to match your data)\n",
    "region_cols = list(inp_df.loc[:, \"VA/2\":\"VA/2035\"].columns)\n",
    "labels = inp_df[\"DX\"].values\n",
    "ids = inp_df[\"SUBJ_ID\"].values\n",
    "\n",
    "# Fit LDA on combined z-scores\n",
    "lda = LDATopicModel(n_topics=N_TOPICS)\n",
    "theta = lda.fit_transform(inp_df[region_cols])\n",
    "\n",
    "# Fit classifier\n",
    "classifier = TopicClassifier(n_splits=5)\n",
    "classifier.fit(theta, labels)\n",
    "cv_results = classifier.cross_validate(theta, labels, ids, verbose=True)\n",
    "\n",
    "print(f\"CV Accuracy: {cv_results['accuracy']:.4f}\")\n",
    "\n",
    "# visualizer = CopathologyVisualizer(\n",
    "#     output_dir='./test/'\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5481570c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Model Internal Visualization ##\n",
    "# print(classifier.get_confusion_matrix())\n",
    "# print(lda.get_topic_patterns())\n",
    "\n",
    "topic_patterns = lda.get_topic_patterns()\n",
    "\n",
    "\n",
    "# fig4 = visualizer.plot_confusion_matrix(\n",
    "#     cm=classifier.get_confusion_matrix(),\n",
    "#     class_names=classifier._classes\n",
    "# )\n",
    "# fig = visualizer.plot_topic_heatmap(\n",
    "#     topic_patterns=topic_patterns,\n",
    "#     region_names=region_cols,\n",
    "#     topic_names=['Thal', 'LF', 'P', 'RT', 'RF', 'LT']\n",
    "# )\n",
    "# fig2 = visualizer.plot_topic_distribution_by_dx(\n",
    "#     theta=lda._theta,\n",
    "#     dx_labels=labels,\n",
    "#     topic_names=['Thal', 'LF', 'P', 'RT', 'RF', 'LT']\n",
    "# )\n",
    "# fig3 = visualizer.plot_diagnosis_topic_profiles(\n",
    "#     theta=lda._theta,\n",
    "#     dx_labels = labels,\n",
    "#     label_map={'Topic_0': 'Thal', 'Topic_1': 'LF', 'Topic_2': 'P', 'Topic_3': 'RT', 'Topic_4': 'RF', 'Topic_5': 'LT'}\n",
    "# )\n",
    "# fig_conf_matrix = visualizer.plot_confusion_matrix(\n",
    "#     cm=classifier.get_confusion_matrix(),\n",
    "#     class_names=classifier._classes,\n",
    "#     accuracy=cv_results['accuracy'],\n",
    "#     title='5-Fold CV Confusion Matrix'\n",
    "# )\n",
    "# prediction_probabilities = visualizer.plot_prediction_probabilities(\n",
    "#     proba_df=classifier.get_cv_results(),\n",
    "#     dx_order = [\"AD\", \"DLB\", \"PD\", \"SVAD\", \"bvFTD\", \"nfvPPA\", \"svPPA\"]\n",
    "# )\n",
    "# probabilities_heatmap = visualizer.plot_probability_heatmap(\n",
    "#     proba_df=classifier.get_cv_results(),\n",
    "#     dx_order = [\"AD\", \"DLB\", \"PD\", \"SVAD\", \"bvFTD\", \"nfvPPA\", \"svPPA\"]\n",
    "# )\n",
    "\n",
    "# top_regions = visualizer.plot_top_regions_per_topic(\n",
    "#     topic_patterns = lda.get_topic_patterns(),\n",
    "#     region_names=region_cols,\n",
    "#     topic_names=['Thal', 'LF', 'P', 'RT', 'RF', 'LT']\n",
    "# )\n",
    "\n",
    "# cv_results = classifier.get_cv_results()\n",
    "# copathology_stacked_bar = visualizer.plot_copathology_stacked_bars(\n",
    "#     theta=lda._theta,\n",
    "#     dx_labels=labels,\n",
    "#     # topic_names=['Topic_0', 'Topic_1', 'Topic_2', 'Topic_3', 'Topic_4', 'Topic_5']\n",
    "#     label_map={'Topic_0': 'Thal', 'Topic_1': 'LF', 'Topic_2': 'P', 'Topic_3': 'RT', 'Topic_4': 'RF', 'Topic_5': 'LT'},\n",
    "#     predictions=cv_results[\"DX_pred\"].values,\n",
    "#     proba_df=cv_results\n",
    "# )\n",
    "\n",
    "# feature_importance = visualizer.plot_feature_importance(\n",
    "#     importance_df=classifier.get_feature_importance()\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bec9f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## ADNI Inference ## 260120\n",
    "adni_raw = pd.read_csv('C:/Users/BREIN/Desktop/copathology_visualization_temp/data/stage_data/ptau_volume_model/ADNI_3.csv')\n",
    "region_cols = adni_raw.loc[:, 'VA/2':'VA/2035'].columns\n",
    "adni_cn = adni_raw[adni_raw['DX'] == 'CN']\n",
    "adni_pat = adni_raw[adni_raw['DX'] != 'CN']\n",
    "\n",
    "adni_stage_df = adni_pat[['FULL_ID', 'DX', 'tau_stage_aa/low', 'tau_stage_aa/mid', 'tau_stage_aa/high', 'pred_tau_stage_aa/low', 'pred_tau_stage_aa/mid', 'pred_tau_stage_aa/high']].dropna()\n",
    "prob_cols = ['pred_tau_stage_aa/low','pred_tau_stage_aa/mid','pred_tau_stage_aa/high']\n",
    "max_col = adni_stage_df[prob_cols].idxmax(axis=1)\n",
    "adni_stage_df[prob_cols] = 0\n",
    "adni_stage_df.loc[:, prob_cols] = (pd.get_dummies(max_col).reindex(columns=prob_cols, fill_value=0).astype(float))\n",
    "stage_map = {\n",
    "    'low': 0,\n",
    "    'mid': 1,\n",
    "    'high': 2\n",
    "}\n",
    "def get_stage(colname):\n",
    "    return stage_map[colname.split('/')[-1]]\n",
    "adni_stage_df['gt_stage'] = (\n",
    "    adni_stage_df[['tau_stage_aa/low', 'tau_stage_aa/mid', 'tau_stage_aa/high']]\n",
    "    .idxmax(axis=1)\n",
    "    .apply(get_stage)\n",
    ")\n",
    "\n",
    "adni_stage_df['pred_stage'] = (\n",
    "    adni_stage_df[prob_cols]\n",
    "    .idxmax(axis=1)\n",
    "    .apply(get_stage)\n",
    ")\n",
    "\n",
    "# --------------------------------\n",
    "# Subject grouping\n",
    "# --------------------------------\n",
    "adni_lower_than_pred = adni_stage_df[\n",
    "    adni_stage_df['gt_stage'] < adni_stage_df['pred_stage']\n",
    "][['FULL_ID', 'DX', 'gt_stage', 'pred_stage']]\n",
    "\n",
    "adni_exact_match = adni_stage_df[\n",
    "    adni_stage_df['gt_stage'] == adni_stage_df['pred_stage']\n",
    "][['FULL_ID', 'DX', 'gt_stage', 'pred_stage']]\n",
    "\n",
    "## Inference ##\n",
    "adni_prep = DataProcessor(\n",
    "    region_cols=region_cols,\n",
    "    dx_col='DX',\n",
    "    subject_col='FULL_ID'\n",
    ")\n",
    "adni_prep.fit_baseline(hc_data=adni_cn)\n",
    "adni_Z = adni_prep.compute_atrophy_scores(data=adni_pat)\n",
    "print(adni_Z.shape)\n",
    "print(adni_cn.shape)\n",
    "\n",
    "adni_theta = lda.transform(adni_Z)\n",
    "adni_y_pred = classifier.predict(adni_theta)\n",
    "adni_y_proba = classifier.predict_proba(adni_theta)\n",
    "\n",
    "adni_results = pd.DataFrame(adni_theta, columns=[f\"Topic_{k}\" for k in range(lda.n_topics)])\n",
    "print(adni_results.shape)\n",
    "\n",
    "subj_col = adni_prep.subject_col\n",
    "if subj_col in adni_pat.columns:\n",
    "    adni_results.insert(0, \"SUBJ_ID\", adni_pat[subj_col].values)\n",
    "\n",
    "adni_results['pred_DX'] = adni_y_pred\n",
    "for i, dx in enumerate(classifier.classes):\n",
    "    adni_results[f\"P({dx})\"] = adni_y_proba[:,i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "878c9c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# FIGURE 1 — INDIVIDUAL SUBJECT DX PROFILES (grouped by DX)\n",
    "# ============================================================\n",
    "\n",
    "subject_order_dict = {}  # save the order for Figure 2\n",
    "\n",
    "for group in df[\"stage_group\"].unique():\n",
    "\n",
    "    df_g = df[df[\"stage_group\"] == group].copy()\n",
    "    if df_g.shape[0] < min_subjects:\n",
    "        continue\n",
    "\n",
    "    # Sort subjects by DX groups, then by P(AD) within DX\n",
    "    subject_order = []\n",
    "    dx_values = df_g[\"DX\"].unique()\n",
    "    dx_boundaries = []  # store start of each DX group\n",
    "    current_idx = 0\n",
    "\n",
    "    for dx in dx_values:\n",
    "        df_dx = df_g[df_g[\"DX\"] == dx].copy()\n",
    "        df_dx = df_dx.sort_values(f\"P({target_dx})\", ascending=False)\n",
    "        subject_order.extend(df_dx[\"SUBJ_ID\"].tolist())\n",
    "\n",
    "        dx_count = df_dx.shape[0]\n",
    "        dx_boundaries.append((current_idx, current_idx + dx_count, dx))\n",
    "        current_idx += dx_count\n",
    "\n",
    "    # save order for topic plot\n",
    "    subject_order_dict[group] = subject_order\n",
    "\n",
    "    # Reorder df_g\n",
    "    df_g = df_g.set_index(\"SUBJ_ID\").loc[subject_order]\n",
    "\n",
    "    # stacked DX probability bar\n",
    "    fig, ax = plt.subplots(figsize=(12, 4))\n",
    "    bottom = np.zeros(len(df_g))\n",
    "\n",
    "    for i, col in enumerate(prob_cols):\n",
    "        ax.bar(\n",
    "            np.arange(len(df_g)),\n",
    "            df_g[col].values,\n",
    "            bottom=bottom,\n",
    "            color=colors_dx[i],\n",
    "            width=1.0,\n",
    "            label=dx_labels[i]\n",
    "        )\n",
    "        bottom += df_g[col].values\n",
    "\n",
    "    ax.set_ylim(0, 1)\n",
    "    ax.set_xticks([])  # we will add custom DX labels\n",
    "\n",
    "    # Add vertical lines and DX labels\n",
    "    for start, end, dx in dx_boundaries:\n",
    "        ax.axvline(start - 0.5, color='black', linewidth=1.2)\n",
    "        ax.text((start + end) / 2 - 0.5, -0.05, dx,\n",
    "                ha='center', va='top', fontsize=12)\n",
    "    ax.axvline(end - 0.5, color='black', linewidth=1.2)\n",
    "\n",
    "    ax.set_ylabel(\"Predicted DX probability\")\n",
    "    ax.set_title(f\"{group} subjects — grouped by DX, ordered by P({target_dx})\")\n",
    "\n",
    "    ax.legend(\n",
    "        title=\"Predicted DX\",\n",
    "        bbox_to_anchor=(1.02, 1),\n",
    "        loc=\"upper left\"\n",
    "    )\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# FIGURE 2 — TOPIC DISTRIBUTION PER SUBJECT\n",
    "# ============================================================\n",
    "\n",
    "topic_cols = list(label_map.keys())\n",
    "topic_labels = [label_map[t] for t in topic_cols]\n",
    "colors_topic = sns.color_palette(\"Dark2\", len(topic_cols))\n",
    "\n",
    "for group in df[\"stage_group\"].unique():\n",
    "\n",
    "    subj_order = subject_order_dict[group]\n",
    "    df_g = df[df[\"SUBJ_ID\"].isin(subj_order)].copy()\n",
    "    df_g = df_g.set_index(\"SUBJ_ID\").loc[subj_order]\n",
    "\n",
    "    # Determine DX boundaries\n",
    "    dx_values = df_g[\"DX\"].unique()\n",
    "    dx_boundaries = []\n",
    "    current_idx = 0\n",
    "    for dx in dx_values:\n",
    "        df_dx = df_g[df_g[\"DX\"] == dx]\n",
    "        dx_count = df_dx.shape[0]\n",
    "        dx_boundaries.append((current_idx, current_idx + dx_count, dx))\n",
    "        current_idx += dx_count\n",
    "\n",
    "    # Plot stacked topic bar\n",
    "    fig, ax = plt.subplots(figsize=(12, 4))\n",
    "    bottom = np.zeros(len(df_g))\n",
    "\n",
    "    for i, col in enumerate(topic_cols):\n",
    "        ax.bar(\n",
    "            np.arange(len(df_g)),\n",
    "            df_g[col].values,\n",
    "            bottom=bottom,\n",
    "            color=colors_topic[i],\n",
    "            width=1.0,\n",
    "            label=topic_labels[i]\n",
    "        )\n",
    "        bottom += df_g[col].values\n",
    "\n",
    "    ax.set_ylim(0, 1)\n",
    "    ax.set_xticks([])\n",
    "\n",
    "    # Add vertical lines and DX labels\n",
    "    for start, end, dx in dx_boundaries:\n",
    "        ax.axvline(start - 0.5, color='black', linewidth=1.2)\n",
    "        ax.text((start + end) / 2 - 0.5, -0.05, dx,\n",
    "                ha='center', va='top', fontsize=12)\n",
    "    ax.axvline(end - 0.5, color='black', linewidth=1.2)\n",
    "\n",
    "    ax.set_ylabel(\"Topic weight\")\n",
    "    ax.set_title(f\"{group} subjects — topic distribution grouped by DX\")\n",
    "\n",
    "    ax.legend(\n",
    "        title=\"Topics\",\n",
    "        bbox_to_anchor=(1.02, 1),\n",
    "        loc=\"upper left\",\n",
    "        ncol=1\n",
    "    )\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0822a367",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# ============================================================\n",
    "# SETTINGS\n",
    "# ============================================================\n",
    "label_map = {'Topic_0': 'Thal', 'Topic_1': 'LF', 'Topic_2': 'P',\n",
    "             'Topic_3': 'RT', 'Topic_4': 'RF', 'Topic_5': 'LT'}\n",
    "target_dx = \"AD\"\n",
    "min_subjects = 5\n",
    "\n",
    "prob_cols = [c for c in adni_results.columns if c.startswith(\"P(\")]\n",
    "dx_labels = [c.replace(\"P(\", \"\").replace(\")\", \"\") for c in prob_cols]\n",
    "\n",
    "topic_cols = [c for c in adni_results.columns if c.startswith(\"Topic_\")]\n",
    "topic_labels = topic_cols  # can rename if needed\n",
    "\n",
    "colors_dx = sns.color_palette(\"tab10\", len(dx_labels))\n",
    "colors_topic = sns.color_palette(\"tab20\", len(topic_cols))\n",
    "\n",
    "groups = {\n",
    "    \"GT < Pred\": adni_lower_than_pred,\n",
    "    \"GT = Pred\": adni_exact_match\n",
    "}\n",
    "\n",
    "# ============================================================\n",
    "# MERGE STAGING + INFERENCE\n",
    "# ============================================================\n",
    "\n",
    "stage_info = pd.concat(\n",
    "    [\n",
    "        adni_lower_than_pred.assign(stage_group=\"GT < Pred\"),\n",
    "        adni_exact_match.assign(stage_group=\"GT = Pred\")\n",
    "    ],\n",
    "    axis=0\n",
    ")\n",
    "\n",
    "df = adni_results.merge(\n",
    "    stage_info,\n",
    "    left_on=\"SUBJ_ID\",\n",
    "    right_on=\"FULL_ID\",\n",
    "    how=\"inner\"\n",
    ")\n",
    "\n",
    "print(\"Subjects included:\", df.shape[0])\n",
    "# ============================================================\n",
    "# FIGURE 1 — INDIVIDUAL SUBJECT DX PROFILES (grouped by DX)\n",
    "# ============================================================\n",
    "\n",
    "subject_order_dict = {}  # save the order for Figure 2\n",
    "\n",
    "for group in df[\"stage_group\"].unique():\n",
    "\n",
    "    df_g = df[df[\"stage_group\"] == group].copy()\n",
    "    if df_g.shape[0] < min_subjects:\n",
    "        continue\n",
    "\n",
    "    # Sort subjects by DX groups, then by P(AD) within DX\n",
    "    subject_order = []\n",
    "    # dx_values = df_g[\"DX\"].unique()\n",
    "    dx_values = ['MCI', 'Dementia']\n",
    "    dx_boundaries = []  # store start of each DX group\n",
    "    current_idx = 0\n",
    "\n",
    "    for dx in dx_values:\n",
    "        df_dx = df_g[df_g[\"DX\"] == dx].copy()\n",
    "        df_dx = df_dx.sort_values(f\"P({target_dx})\", ascending=False)\n",
    "        subject_order.extend(df_dx[\"SUBJ_ID\"].tolist())\n",
    "\n",
    "        dx_count = df_dx.shape[0]\n",
    "        dx_boundaries.append((current_idx, current_idx + dx_count, dx))\n",
    "        current_idx += dx_count\n",
    "\n",
    "    # save order for topic plot\n",
    "    subject_order_dict[group] = subject_order\n",
    "\n",
    "    # Reorder df_g\n",
    "    df_g = df_g.set_index(\"SUBJ_ID\").loc[subject_order]\n",
    "\n",
    "    # stacked DX probability bar\n",
    "    fig, ax = plt.subplots(figsize=(12, 4))\n",
    "    bottom = np.zeros(len(df_g))\n",
    "\n",
    "    for i, col in enumerate(prob_cols):\n",
    "        ax.bar(\n",
    "            np.arange(len(df_g)),\n",
    "            df_g[col].values,\n",
    "            bottom=bottom,\n",
    "            color=colors_dx[i],\n",
    "            width=1.0,\n",
    "            label=dx_labels[i]\n",
    "        )\n",
    "        bottom += df_g[col].values\n",
    "\n",
    "    ax.set_ylim(0, 1)\n",
    "    ax.set_xticks([])  # we will add custom DX labels\n",
    "\n",
    "    # Add vertical lines and DX labels\n",
    "    for start, end, dx in dx_boundaries:\n",
    "        ax.axvline(start - 0.5, color='black', linewidth=1.2)\n",
    "        ax.text((start + end) / 2 - 0.5, -0.05, dx,\n",
    "                ha='center', va='top', fontsize=12)\n",
    "    ax.axvline(end - 0.5, color='black', linewidth=1.2)\n",
    "\n",
    "    ax.set_ylabel(\"Predicted DX probability\")\n",
    "    ax.set_title(f\"{group} subjects — grouped by DX, ordered by P({target_dx})\")\n",
    "\n",
    "    ax.legend(\n",
    "        title=\"Predicted DX\",\n",
    "        bbox_to_anchor=(1.02, 1),\n",
    "        loc=\"upper left\"\n",
    "    )\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# FIGURE 2 — TOPIC DISTRIBUTION PER SUBJECT\n",
    "# ============================================================\n",
    "\n",
    "topic_cols = list(label_map.keys())\n",
    "topic_labels = [label_map[t] for t in topic_cols]\n",
    "colors_topic = sns.color_palette(\"Dark2\", len(topic_cols))\n",
    "\n",
    "for group in df[\"stage_group\"].unique():\n",
    "\n",
    "    subj_order = subject_order_dict[group]\n",
    "    df_g = df[df[\"SUBJ_ID\"].isin(subj_order)].copy()\n",
    "    df_g = df_g.set_index(\"SUBJ_ID\").loc[subj_order]\n",
    "\n",
    "    # Determine DX boundaries\n",
    "    # dx_values = df_g[\"DX\"].unique()\n",
    "    dx_values = ['MCI', 'Dementia']\n",
    "    dx_boundaries = []\n",
    "    current_idx = 0\n",
    "    for dx in dx_values:\n",
    "        df_dx = df_g[df_g[\"DX\"] == dx]\n",
    "        dx_count = df_dx.shape[0]\n",
    "        dx_boundaries.append((current_idx, current_idx + dx_count, dx))\n",
    "        current_idx += dx_count\n",
    "\n",
    "    # Plot stacked topic bar\n",
    "    fig, ax = plt.subplots(figsize=(12, 4))\n",
    "    bottom = np.zeros(len(df_g))\n",
    "\n",
    "    for i, col in enumerate(topic_cols):\n",
    "        ax.bar(\n",
    "            np.arange(len(df_g)),\n",
    "            df_g[col].values,\n",
    "            bottom=bottom,\n",
    "            color=colors_topic[i],\n",
    "            width=1.0,\n",
    "            label=topic_labels[i]\n",
    "        )\n",
    "        bottom += df_g[col].values\n",
    "\n",
    "    ax.set_ylim(0, 1)\n",
    "    ax.set_xticks([])\n",
    "\n",
    "    # Add vertical lines and DX labels\n",
    "    for start, end, dx in dx_boundaries:\n",
    "        ax.axvline(start - 0.5, color='black', linewidth=1.2)\n",
    "        ax.text((start + end) / 2 - 0.5, -0.05, dx,\n",
    "                ha='center', va='top', fontsize=12)\n",
    "    ax.axvline(end - 0.5, color='black', linewidth=1.2)\n",
    "\n",
    "    ax.set_ylabel(\"Topic weight\")\n",
    "    ax.set_title(f\"{group} subjects — topic distribution grouped by DX\")\n",
    "\n",
    "    ax.legend(\n",
    "        title=\"Topics\",\n",
    "        bbox_to_anchor=(1.02, 1),\n",
    "        loc=\"upper left\",\n",
    "        ncol=1\n",
    "    )\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# ============================================================\n",
    "# FIGURE 3 — MEAN DX COMPOSITION\n",
    "# ============================================================\n",
    "\n",
    "mean_df = (\n",
    "    df.groupby(\"stage_group\")[prob_cols]\n",
    "    .mean()\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(7, 4))\n",
    "bottom = np.zeros(mean_df.shape[0])\n",
    "\n",
    "for i, col in enumerate(prob_cols):\n",
    "    ax.bar(\n",
    "        mean_df[\"stage_group\"],\n",
    "        mean_df[col],\n",
    "        bottom=bottom,\n",
    "        color=colors_dx[i],\n",
    "        label=dx_labels[i]\n",
    "    )\n",
    "    bottom += mean_df[col].values\n",
    "\n",
    "ax.set_ylim(0, 1)\n",
    "ax.set_ylabel(\"Mean predicted probability\")\n",
    "ax.set_title(\"Predicted DX enrichment by tau-stage mismatch\")\n",
    "\n",
    "ax.legend(\n",
    "    title=\"Predicted DX\",\n",
    "    bbox_to_anchor=(1.02, 1),\n",
    "    loc=\"upper left\"\n",
    ")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ============================================================\n",
    "# FIGURE 4 — COPATHOLOGY INDEX\n",
    "# ============================================================\n",
    "\n",
    "# define non-AD copathology signal\n",
    "non_ad_cols = [c for c in prob_cols if \"AD\" not in c]\n",
    "df[\"copath_index\"] = df[non_ad_cols].sum(axis=1)\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.boxplot(\n",
    "    data=df,\n",
    "    x=\"stage_group\",\n",
    "    y=\"copath_index\"\n",
    ")\n",
    "\n",
    "plt.ylabel(\"Non-AD copathology probability\")\n",
    "plt.title(\"Copathology enrichment in tau-stage mismatch\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3229f399",
   "metadata": {},
   "outputs": [],
   "source": [
    "## ADNI4 Inference ## 260120\n",
    "adni4_raw = pd.read_csv('C:/Users/BREIN/Desktop/copathology_visualization_temp/data/stage_data/ptau_volume_model/ADNI4_3.csv')\n",
    "region_cols = adni4_raw.loc[:, 'VA/2':'VA/2035'].columns\n",
    "adni4_raw = adni4_raw.dropna(subset=region_cols)\n",
    "adni4_cn = adni4_raw[adni4_raw['DX'] == 'CN']\n",
    "adni4_pat = adni4_raw[adni4_raw['DX'] != 'CN']\n",
    "adni4_stage_df = adni4_pat[['FULL_ID', 'DX', 'tau_stage_aa/low', 'tau_stage_aa/mid', 'tau_stage_aa/high', 'pred_tau_stage_aa/low', 'pred_tau_stage_aa/mid', 'pred_tau_stage_aa/high']].dropna()\n",
    "prob_cols = ['pred_tau_stage_aa/low','pred_tau_stage_aa/mid','pred_tau_stage_aa/high']\n",
    "max_col = adni4_stage_df[prob_cols].idxmax(axis=1)\n",
    "adni4_stage_df[prob_cols] = 0\n",
    "adni4_stage_df.loc[:, prob_cols] = (pd.get_dummies(max_col).reindex(columns=prob_cols, fill_value=0).astype(float))\n",
    "stage_map = {\n",
    "    'low': 0,\n",
    "    'mid': 1,\n",
    "    'high': 2\n",
    "}\n",
    "def get_stage(colname):\n",
    "    return stage_map[colname.split('/')[-1]]\n",
    "adni4_stage_df['gt_stage'] = (\n",
    "    adni4_stage_df[['tau_stage_aa/low', 'tau_stage_aa/mid', 'tau_stage_aa/high']]\n",
    "    .idxmax(axis=1)\n",
    "    .apply(get_stage)\n",
    ")\n",
    "\n",
    "adni4_stage_df['pred_stage'] = (\n",
    "    adni4_stage_df[prob_cols]\n",
    "    .idxmax(axis=1)\n",
    "    .apply(get_stage)\n",
    ")\n",
    "\n",
    "# --------------------------------\n",
    "# Subject grouping\n",
    "# --------------------------------\n",
    "adni4_lower_than_pred = adni4_stage_df[\n",
    "    adni4_stage_df['gt_stage'] < adni4_stage_df['pred_stage']\n",
    "][['FULL_ID', 'DX', 'gt_stage', 'pred_stage']]\n",
    "\n",
    "adni4_exact_match = adni4_stage_df[\n",
    "    adni4_stage_df['gt_stage'] == adni4_stage_df['pred_stage']\n",
    "][['FULL_ID', 'DX', 'gt_stage', 'pred_stage']]\n",
    "\n",
    "\n",
    "\n",
    "adni4_prep = DataProcessor(\n",
    "    region_cols=region_cols,\n",
    "    dx_col='DX',\n",
    "    subject_col='FULL_ID'\n",
    ")\n",
    "adni4_prep.fit_baseline(hc_data=adni4_cn)\n",
    "adni4_Z = adni4_prep.compute_atrophy_scores(data=adni4_pat)\n",
    "print(adni4_Z.shape)\n",
    "print(adni4_cn.shape)\n",
    "\n",
    "adni4_theta = lda.transform(adni4_Z)\n",
    "adni4_y_pred = classifier.predict(adni4_theta)\n",
    "adni4_y_proba = classifier.predict_proba(adni4_theta)\n",
    "\n",
    "adni4_results = pd.DataFrame(adni4_theta, columns=[f\"Topic_{k}\" for k in range(lda.n_topics)])\n",
    "print(adni4_results.shape)\n",
    "\n",
    "subj_col = adni4_prep.subject_col\n",
    "if subj_col in adni4_pat.columns:\n",
    "    adni4_results.insert(0, \"SUBJ_ID\", adni4_pat[subj_col].values)\n",
    "\n",
    "adni4_results['pred_DX'] = adni4_y_pred\n",
    "for i, dx in enumerate(classifier.classes):\n",
    "    adni4_results[f\"P({dx})\"] = adni4_y_proba[:,i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a44af472",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# ============================================================\n",
    "# SETTINGS\n",
    "# ============================================================\n",
    "label_map = {'Topic_0': 'Thal', 'Topic_1': 'LF', 'Topic_2': 'P',\n",
    "             'Topic_3': 'RT', 'Topic_4': 'RF', 'Topic_5': 'LT'}\n",
    "target_dx = \"AD\"\n",
    "min_subjects = 5\n",
    "\n",
    "prob_cols = [c for c in adni4_results.columns if c.startswith(\"P(\")]\n",
    "dx_labels = [c.replace(\"P(\", \"\").replace(\")\", \"\") for c in prob_cols]\n",
    "\n",
    "topic_cols = [c for c in adni4_results.columns if c.startswith(\"Topic_\")]\n",
    "topic_labels = topic_cols  # can rename if needed\n",
    "\n",
    "colors_dx = sns.color_palette(\"tab10\", len(dx_labels))\n",
    "colors_topic = sns.color_palette(\"tab20\", len(topic_cols))\n",
    "\n",
    "groups = {\n",
    "    \"GT < Pred\": adni4_lower_than_pred,\n",
    "    \"GT = Pred\": adni4_exact_match\n",
    "}\n",
    "\n",
    "# ============================================================\n",
    "# MERGE STAGING + INFERENCE\n",
    "# ============================================================\n",
    "\n",
    "stage_info = pd.concat(\n",
    "    [\n",
    "        adni4_lower_than_pred.assign(stage_group=\"GT < Pred\"),\n",
    "        adni4_exact_match.assign(stage_group=\"GT = Pred\")\n",
    "    ],\n",
    "    axis=0\n",
    ")\n",
    "\n",
    "df = adni4_results.merge(\n",
    "    stage_info,\n",
    "    left_on=\"SUBJ_ID\",\n",
    "    right_on=\"FULL_ID\",\n",
    "    how=\"inner\"\n",
    ")\n",
    "\n",
    "print(\"Subjects included:\", df.shape[0])\n",
    "# ============================================================\n",
    "# FIGURE 1 — INDIVIDUAL SUBJECT DX PROFILES (grouped by DX)\n",
    "# ============================================================\n",
    "\n",
    "subject_order_dict = {}  # save the order for Figure 2\n",
    "\n",
    "for group in df[\"stage_group\"].unique():\n",
    "\n",
    "    df_g = df[df[\"stage_group\"] == group].copy()\n",
    "    if df_g.shape[0] < min_subjects:\n",
    "        continue\n",
    "\n",
    "    # Sort subjects by DX groups, then by P(AD) within DX\n",
    "    subject_order = []\n",
    "    # dx_values = df_g[\"DX\"].unique()\n",
    "    dx_values = ['MCI', 'AD']\n",
    "    dx_boundaries = []  # store start of each DX group\n",
    "    current_idx = 0\n",
    "\n",
    "    for dx in dx_values:\n",
    "        df_dx = df_g[df_g[\"DX\"] == dx].copy()\n",
    "        df_dx = df_dx.sort_values(f\"P({target_dx})\", ascending=False)\n",
    "        subject_order.extend(df_dx[\"SUBJ_ID\"].tolist())\n",
    "\n",
    "        dx_count = df_dx.shape[0]\n",
    "        dx_boundaries.append((current_idx, current_idx + dx_count, dx))\n",
    "        current_idx += dx_count\n",
    "\n",
    "    # save order for topic plot\n",
    "    subject_order_dict[group] = subject_order\n",
    "\n",
    "    # Reorder df_g\n",
    "    df_g = df_g.set_index(\"SUBJ_ID\").loc[subject_order]\n",
    "\n",
    "    # stacked DX probability bar\n",
    "    fig, ax = plt.subplots(figsize=(12, 4))\n",
    "    bottom = np.zeros(len(df_g))\n",
    "\n",
    "    for i, col in enumerate(prob_cols):\n",
    "        ax.bar(\n",
    "            np.arange(len(df_g)),\n",
    "            df_g[col].values,\n",
    "            bottom=bottom,\n",
    "            color=colors_dx[i],\n",
    "            width=1.0,\n",
    "            label=dx_labels[i]\n",
    "        )\n",
    "        bottom += df_g[col].values\n",
    "\n",
    "    ax.set_ylim(0, 1)\n",
    "    ax.set_xticks([])  # we will add custom DX labels\n",
    "\n",
    "    # Add vertical lines and DX labels\n",
    "    for start, end, dx in dx_boundaries:\n",
    "        ax.axvline(start - 0.5, color='black', linewidth=1.2)\n",
    "        ax.text((start + end) / 2 - 0.5, -0.05, dx,\n",
    "                ha='center', va='top', fontsize=12)\n",
    "    ax.axvline(end - 0.5, color='black', linewidth=1.2)\n",
    "\n",
    "    ax.set_ylabel(\"Predicted DX probability\")\n",
    "    ax.set_title(f\"{group} subjects — grouped by DX, ordered by P({target_dx})\")\n",
    "\n",
    "    ax.legend(\n",
    "        title=\"Predicted DX\",\n",
    "        bbox_to_anchor=(1.02, 1),\n",
    "        loc=\"upper left\"\n",
    "    )\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# FIGURE 2 — TOPIC DISTRIBUTION PER SUBJECT\n",
    "# ============================================================\n",
    "\n",
    "topic_cols = list(label_map.keys())\n",
    "topic_labels = [label_map[t] for t in topic_cols]\n",
    "colors_topic = sns.color_palette(\"Dark2\", len(topic_cols))\n",
    "\n",
    "for group in df[\"stage_group\"].unique():\n",
    "\n",
    "    subj_order = subject_order_dict[group]\n",
    "    df_g = df[df[\"SUBJ_ID\"].isin(subj_order)].copy()\n",
    "    df_g = df_g.set_index(\"SUBJ_ID\").loc[subj_order]\n",
    "\n",
    "    # Determine DX boundaries\n",
    "    # dx_values = df_g[\"DX\"].unique()\n",
    "    dx_values = ['MCI', 'AD']\n",
    "    dx_boundaries = []\n",
    "    current_idx = 0\n",
    "    for dx in dx_values:\n",
    "        df_dx = df_g[df_g[\"DX\"] == dx]\n",
    "        dx_count = df_dx.shape[0]\n",
    "        dx_boundaries.append((current_idx, current_idx + dx_count, dx))\n",
    "        current_idx += dx_count\n",
    "\n",
    "    # Plot stacked topic bar\n",
    "    fig, ax = plt.subplots(figsize=(12, 4))\n",
    "    bottom = np.zeros(len(df_g))\n",
    "\n",
    "    for i, col in enumerate(topic_cols):\n",
    "        ax.bar(\n",
    "            np.arange(len(df_g)),\n",
    "            df_g[col].values,\n",
    "            bottom=bottom,\n",
    "            color=colors_topic[i],\n",
    "            width=1.0,\n",
    "            label=topic_labels[i]\n",
    "        )\n",
    "        bottom += df_g[col].values\n",
    "\n",
    "    ax.set_ylim(0, 1)\n",
    "    ax.set_xticks([])\n",
    "\n",
    "    # Add vertical lines and DX labels\n",
    "    for start, end, dx in dx_boundaries:\n",
    "        ax.axvline(start - 0.5, color='black', linewidth=1.2)\n",
    "        ax.text((start + end) / 2 - 0.5, -0.05, dx,\n",
    "                ha='center', va='top', fontsize=12)\n",
    "    ax.axvline(end - 0.5, color='black', linewidth=1.2)\n",
    "\n",
    "    ax.set_ylabel(\"Topic weight\")\n",
    "    ax.set_title(f\"{group} subjects — topic distribution grouped by DX\")\n",
    "\n",
    "    ax.legend(\n",
    "        title=\"Topics\",\n",
    "        bbox_to_anchor=(1.02, 1),\n",
    "        loc=\"upper left\",\n",
    "        ncol=1\n",
    "    )\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# ============================================================\n",
    "# FIGURE 3 — MEAN DX COMPOSITION\n",
    "# ============================================================\n",
    "\n",
    "mean_df = (\n",
    "    df.groupby(\"stage_group\")[prob_cols]\n",
    "    .mean()\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(7, 4))\n",
    "bottom = np.zeros(mean_df.shape[0])\n",
    "\n",
    "for i, col in enumerate(prob_cols):\n",
    "    ax.bar(\n",
    "        mean_df[\"stage_group\"],\n",
    "        mean_df[col],\n",
    "        bottom=bottom,\n",
    "        color=colors_dx[i],\n",
    "        label=dx_labels[i]\n",
    "    )\n",
    "    bottom += mean_df[col].values\n",
    "\n",
    "ax.set_ylim(0, 1)\n",
    "ax.set_ylabel(\"Mean predicted probability\")\n",
    "ax.set_title(\"Predicted DX enrichment by tau-stage mismatch\")\n",
    "\n",
    "ax.legend(\n",
    "    title=\"Predicted DX\",\n",
    "    bbox_to_anchor=(1.02, 1),\n",
    "    loc=\"upper left\"\n",
    ")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ============================================================\n",
    "# FIGURE 4 — COPATHOLOGY INDEX\n",
    "# ============================================================\n",
    "\n",
    "# define non-AD copathology signal\n",
    "non_ad_cols = [c for c in prob_cols if \"AD\" not in c]\n",
    "df[\"copath_index\"] = df[non_ad_cols].sum(axis=1)\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.boxplot(\n",
    "    data=df,\n",
    "    x=\"stage_group\",\n",
    "    y=\"copath_index\"\n",
    ")\n",
    "\n",
    "plt.ylabel(\"Non-AD copathology probability\")\n",
    "plt.title(\"Copathology enrichment in tau-stage mismatch\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6341a53c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## NACC Inference ## 260120\n",
    "from data_processor import *\n",
    "nacc_raw = pd.read_csv('C:/Users/BREIN/Desktop/copathology_visualization_temp/data/nacc/260120_NACC_VA_TAU_PATH_matched.csv')\n",
    "# nacc_raw.rename(columns=col_map)\n",
    "region_cols = nacc_raw.loc[:, 'VA/2':'VA/2035'].columns\n",
    "pathology_cols = nacc_raw.loc[:, 'NACC_AD':'NACC_svPPA'].columns\n",
    "nacc_filtered = nacc_raw[nacc_raw['DX'] != 'Unknown']\n",
    "\n",
    "nacc_cn = nacc_filtered[nacc_filtered['DX'] == 'CN']\n",
    "nacc_pat = nacc_filtered[nacc_filtered['DX'] != 'CN']\n",
    "\n",
    "print(nacc_cn.shape)\n",
    "print(nacc_pat.shape)\n",
    "\n",
    "nacc_prep = DataProcessor(\n",
    "    region_cols=region_cols,\n",
    "    dx_col='DX',\n",
    "    subject_col='subject_id'\n",
    ")\n",
    "nacc_prep.fit_baseline(hc_data=nacc_cn)\n",
    "nacc_Z = nacc_prep.compute_atrophy_scores(data=nacc_pat)\n",
    "print(type(nacc_Z))\n",
    "\n",
    "nacc_theta = lda.transform(nacc_Z)\n",
    "y_pred = classifier.predict(nacc_theta)\n",
    "y_proba = classifier.predict_proba(nacc_theta)\n",
    "# print(nacc_theta.shape)\n",
    "# print(y_pred.shape)\n",
    "# print(y_proba.shape)\n",
    "\n",
    "nacc_results = pd.DataFrame(nacc_theta, columns=[f\"Topic_{k}\" for k in range(lda.n_topics)])\n",
    "print(nacc_results.shape)\n",
    "\n",
    "subj_col = nacc_prep.subject_col\n",
    "if subj_col in nacc_pat.columns:\n",
    "    nacc_results.insert(0, \"SUBJ_ID\", nacc_pat[subj_col].values)\n",
    "\n",
    "nacc_results['pred_DX'] = y_pred\n",
    "for i, dx in enumerate(classifier.classes):\n",
    "    nacc_results[f\"P({dx})\"] = y_proba[:,i]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a024e531",
   "metadata": {},
   "source": [
    "***Inference Visualization TESTS***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fde4fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from math import ceil\n",
    "from itertools import cycle\n",
    "\n",
    "viz_df = nacc_results.merge(\n",
    "    nacc_pat[[nacc_prep.subject_col] + list(pathology_cols)],\n",
    "    left_on=\"SUBJ_ID\",\n",
    "    right_on=nacc_prep.subject_col,\n",
    "    how=\"left\"\n",
    ")\n",
    "# -----------------------------\n",
    "# Topic label map\n",
    "# -----------------------------\n",
    "label_map = {\n",
    "    'Topic_0': 'Thal',\n",
    "    'Topic_1': 'LF',\n",
    "    'Topic_2': 'P',\n",
    "    'Topic_3': 'RT',\n",
    "    'Topic_4': 'RF',\n",
    "    'Topic_5': 'LT'\n",
    "}\n",
    "\n",
    "topic_cols = list(label_map.keys())\n",
    "topic_labels = [label_map[t] for t in topic_cols]\n",
    "\n",
    "# -----------------------------\n",
    "# Radar utilities\n",
    "# -----------------------------\n",
    "def compute_topic_profile(df):\n",
    "    values = df[topic_cols].mean().values\n",
    "    return np.concatenate([values, [values[0]]])\n",
    "\n",
    "\n",
    "def radar_angles(n):\n",
    "    angles = np.linspace(0, 2 * np.pi, n, endpoint=False)\n",
    "    return np.concatenate([angles, [angles[0]]])\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Main visualization\n",
    "# -----------------------------\n",
    "def plot_pathology_radar_panels(\n",
    "    viz_df,\n",
    "    pathology_cols,\n",
    "    min_subjects=1,\n",
    "    ncols=4\n",
    "):\n",
    "    \"\"\"\n",
    "    Creates:\n",
    "    1) Grid of individual pathology radar plots\n",
    "    2) One large combined radar plot\n",
    "    \"\"\"\n",
    "\n",
    "    # -------------------------\n",
    "    # collect valid pathologies\n",
    "    # -------------------------\n",
    "    valid = []\n",
    "    for p in pathology_cols:\n",
    "        n = (viz_df[p] == 1).sum()\n",
    "        if n >= min_subjects:\n",
    "            valid.append((p, n))\n",
    "\n",
    "    if len(valid) == 0:\n",
    "        print(\"No pathology columns with positive subjects.\")\n",
    "        return\n",
    "\n",
    "    angles = radar_angles(len(topic_cols))\n",
    "    colors = plt.cm.tab10.colors\n",
    "    color_cycle = cycle(colors)\n",
    "\n",
    "    # ======================================================\n",
    "    # 1. INDIVIDUAL RADAR SUBPLOTS\n",
    "    # ======================================================\n",
    "    n_panels = len(valid)\n",
    "    nrows = ceil(n_panels / ncols)\n",
    "\n",
    "    fig, axes = plt.subplots(\n",
    "        nrows=nrows,\n",
    "        ncols=ncols,\n",
    "        figsize=(4 * ncols, 4 * nrows),\n",
    "        subplot_kw=dict(polar=True)\n",
    "    )\n",
    "\n",
    "    axes = np.array(axes).reshape(-1)\n",
    "\n",
    "    for ax, (pathology, n_pos) in zip(axes, valid):\n",
    "\n",
    "        pos_df = viz_df[viz_df[pathology] == 1]\n",
    "        values = compute_topic_profile(pos_df)\n",
    "        color = next(color_cycle)\n",
    "\n",
    "        ax.plot(angles, values, linewidth=2.5, color=color)\n",
    "        ax.fill(angles, values, alpha=0.25, color=color)\n",
    "\n",
    "        ax.set_thetagrids(\n",
    "            angles[:-1] * 180 / np.pi,\n",
    "            topic_labels,\n",
    "            fontsize=10\n",
    "        )\n",
    "\n",
    "        ax.set_title(f\"{pathology}\\n(n={n_pos})\", fontsize=11, pad=12)\n",
    "\n",
    "    # remove unused axes\n",
    "    for ax in axes[len(valid):]:\n",
    "        ax.remove()\n",
    "\n",
    "    fig.suptitle(\n",
    "        \"Topic Expression by Copathology (Positive Subjects Only)\",\n",
    "        fontsize=16,\n",
    "        y=1.02\n",
    "    )\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # ======================================================\n",
    "    # 2. COMBINED RADAR OVERLAY\n",
    "    # ======================================================\n",
    "    plt.figure(figsize=(9, 9))\n",
    "    ax = plt.subplot(111, polar=True)\n",
    "\n",
    "    legend_labels = []\n",
    "    color_cycle = cycle(colors)\n",
    "\n",
    "    for pathology, n_pos in valid:\n",
    "\n",
    "        pos_df = viz_df[viz_df[pathology] == 1]\n",
    "        values = compute_topic_profile(pos_df)\n",
    "        color = next(color_cycle)\n",
    "\n",
    "        ax.plot(angles, values, linewidth=2.5, color=color)\n",
    "        ax.fill(angles, values, alpha=0.12, color=color)\n",
    "\n",
    "        legend_labels.append(f\"{pathology} (n={n_pos})\")\n",
    "\n",
    "    ax.set_thetagrids(\n",
    "        angles[:-1] * 180 / np.pi,\n",
    "        topic_labels,\n",
    "        fontsize=12\n",
    "    )\n",
    "\n",
    "    ax.set_title(\n",
    "        \"Combined Topic Profiles Across Copathologies\",\n",
    "        fontsize=16,\n",
    "        pad=30\n",
    "    )\n",
    "\n",
    "    ax.legend(\n",
    "        legend_labels,\n",
    "        bbox_to_anchor=(1.35, 1.1),\n",
    "        loc=\"upper right\",\n",
    "        frameon=False\n",
    "    )\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "plot_pathology_radar_panels(\n",
    "    viz_df=viz_df,\n",
    "    pathology_cols=pathology_cols,\n",
    "    ncols=4\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efc8902c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# ---------------------------------------\n",
    "# settings\n",
    "# ---------------------------------------\n",
    "target_dx = \"AD\"           # sort by P(AD)\n",
    "min_subjects = 5           # skip tiny groups\n",
    "\n",
    "prob_cols = [c for c in viz_df.columns if c.startswith(\"P(\")]\n",
    "dx_labels = [c.replace(\"P(\", \"\").replace(\")\", \"\") for c in prob_cols]\n",
    "\n",
    "colors = sns.color_palette(\"tab10\", len(dx_labels))\n",
    "\n",
    "\n",
    "# ---------------------------------------\n",
    "# loop over each pathology\n",
    "# ---------------------------------------\n",
    "for path in pathology_cols:\n",
    "\n",
    "    # select pathology-positive subjects\n",
    "    df_pos = viz_df[viz_df[path] == 1].copy()\n",
    "\n",
    "    if df_pos.shape[0] < min_subjects:\n",
    "        continue\n",
    "\n",
    "    sort_col = f\"P({target_dx})\"\n",
    "    if sort_col not in df_pos.columns:\n",
    "        continue\n",
    "\n",
    "    # sort subjects by predicted AD probability\n",
    "    df_pos = df_pos.sort_values(\n",
    "        by=sort_col,\n",
    "        ascending=False\n",
    "    ).reset_index(drop=True)\n",
    "\n",
    "    # ---------------------------------------\n",
    "    # stacked probability plot\n",
    "    # ---------------------------------------\n",
    "    fig, ax = plt.subplots(figsize=(12, 4))\n",
    "\n",
    "    bottom = np.zeros(len(df_pos))\n",
    "\n",
    "    for i, (dx, col) in enumerate(zip(dx_labels, prob_cols)):\n",
    "        ax.bar(\n",
    "            np.arange(len(df_pos)),\n",
    "            df_pos[col].values,\n",
    "            bottom=bottom,\n",
    "            color=colors[i],\n",
    "            label=dx,\n",
    "            width=1.0\n",
    "        )\n",
    "        bottom += df_pos[col].values\n",
    "\n",
    "    ax.set_ylim(0, 1)\n",
    "    ax.set_xlim(-0.5, len(df_pos) - 0.5)\n",
    "\n",
    "    ax.set_xticks([])\n",
    "    ax.set_ylabel(\"Predicted diagnosis probability\")\n",
    "\n",
    "    ax.set_title(\n",
    "        f\"{path}+ subjects (n={len(df_pos)}) — sorted by P({target_dx})\",\n",
    "        fontsize=13\n",
    "    )\n",
    "\n",
    "    ax.legend(\n",
    "        title=\"Predicted DX\",\n",
    "        bbox_to_anchor=(1.02, 1),\n",
    "        loc=\"upper left\"\n",
    "    )\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "733ca0b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "target_dx = \"AD\"\n",
    "min_subjects = 5\n",
    "\n",
    "prob_cols = [c for c in viz_df.columns if c.startswith(\"P(\")]\n",
    "dx_labels = [c.replace(\"P(\", \"\").replace(\")\", \"\") for c in prob_cols]\n",
    "\n",
    "for path in pathology_cols:\n",
    "\n",
    "    df_pos = viz_df[viz_df[path] == 1].copy()\n",
    "\n",
    "    if df_pos.shape[0] < min_subjects:\n",
    "        continue\n",
    "\n",
    "    sort_col = f\"P({target_dx})\"\n",
    "    if sort_col not in df_pos.columns:\n",
    "        continue\n",
    "\n",
    "    # 🔥 order subjects by AD probability\n",
    "    df_pos = df_pos.sort_values(\n",
    "        by=sort_col,\n",
    "        ascending=False\n",
    "    ).reset_index(drop=True)\n",
    "\n",
    "    # transpose → diagnoses × subjects\n",
    "    heatmap_data = df_pos[prob_cols].T\n",
    "\n",
    "    plt.figure(figsize=(10, 4))\n",
    "\n",
    "    sns.heatmap(\n",
    "        heatmap_data,\n",
    "        cmap=\"Reds\",\n",
    "        vmin=0,\n",
    "        vmax=1,\n",
    "        cbar_kws={\"label\": \"Predicted probability\"},\n",
    "        xticklabels=False\n",
    "    )\n",
    "\n",
    "    plt.yticks(\n",
    "        np.arange(len(dx_labels)) + 0.5,\n",
    "        dx_labels,\n",
    "        rotation=0\n",
    "    )\n",
    "\n",
    "    plt.xlabel(\"Subjects (ordered by P(AD) ↓)\")\n",
    "    plt.ylabel(\"Predicted diagnosis\")\n",
    "\n",
    "    plt.title(\n",
    "        f\"{path}+ subjects (n={len(df_pos)})\",\n",
    "        fontsize=13\n",
    "    )\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_management",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
