{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "52339eb7",
   "metadata": {},
   "source": [
    "**CN included trainset for LDA+XGB CoPath**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9cc3584",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr  # or spearmanr if you prefer\n",
    "def resilient_subgroup_visualization(inp_df,prob_cols, group_col,group_order,cohort='NACC',scatter_col='standardized_residual'):\n",
    "    group_means = (\n",
    "        inp_df\n",
    "        .groupby(group_col)[prob_cols]\n",
    "        .mean()\n",
    "        .reindex(group_order)\n",
    "    )\n",
    "###################### GROUP MEAN LEVEL #####################\n",
    "    # ------------------------------------------------------------\n",
    "    # Plot heatmap\n",
    "    # ------------------------------------------------------------\n",
    "    plt.figure(figsize=(8, 5))\n",
    "\n",
    "    sns.heatmap(\n",
    "        group_means,\n",
    "        cmap=\"Reds\",\n",
    "        annot=True,\n",
    "        fmt=\".2f\",\n",
    "        linewidths=0.5,\n",
    "        vmin=0,\n",
    "        vmax=1,\n",
    "        cbar_kws={\"label\": \"Mean predicted probability\"}\n",
    "    )\n",
    "\n",
    "    plt.xlabel(\"Predicted pathology\")\n",
    "    plt.ylabel(\"Subgroup\")\n",
    "    plt.title(f\"{cohort} Group-wise Mean Predicted Probability Distribution\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "###################### SUBJECT LEVEL #####################\n",
    "    # ------------------------------------------------------------\n",
    "    # Sort: group first, then descending P(AD)\n",
    "    # ------------------------------------------------------------\n",
    "    inp_df[group_col] = pd.Categorical(\n",
    "        inp_df[group_col],\n",
    "        categories=group_order,\n",
    "        ordered=True\n",
    "    )\n",
    "\n",
    "    df_sorted = (\n",
    "        inp_df\n",
    "        .sort_values([group_col, \"P(AD)\"], ascending=[True, False])\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "\n",
    "\n",
    "    heatmap_data = df_sorted[prob_cols]\n",
    "\n",
    "    # ------------------------------------------------------------\n",
    "    # Compute group positions for y-axis labels\n",
    "    # ------------------------------------------------------------\n",
    "    group_counts = (\n",
    "        df_sorted[group_col]\n",
    "        .value_counts()\n",
    "        .reindex(group_order)\n",
    "    )\n",
    "\n",
    "\n",
    "    group_centers = {}\n",
    "    start = 0\n",
    "\n",
    "    for grp, count in group_counts.items():\n",
    "        center = start + count / 2\n",
    "        group_centers[grp] = center\n",
    "        start += count\n",
    "\n",
    "    # ------------------------------------------------------------\n",
    "    # Plot\n",
    "    # ------------------------------------------------------------\n",
    "    plt.figure(figsize=(10, 10))\n",
    "\n",
    "    ax = sns.heatmap(\n",
    "        heatmap_data,\n",
    "        cmap=\"Reds\",\n",
    "        vmin=0,\n",
    "        vmax=1,\n",
    "        yticklabels=False,\n",
    "        cbar_kws={\"label\": \"Predicted probability\"}\n",
    "    )\n",
    "\n",
    "    # ------------------------------------------------------------\n",
    "    # Horizontal lines between groups\n",
    "    # ------------------------------------------------------------\n",
    "    cum_sizes = np.cumsum(group_counts.values)\n",
    "\n",
    "    for y in cum_sizes[:-1]:\n",
    "        ax.hlines(y, *ax.get_xlim(), colors=\"black\", linewidth=1.5)\n",
    "\n",
    "    # ------------------------------------------------------------\n",
    "    # TN subgroup labels on y-axis\n",
    "    # ------------------------------------------------------------\n",
    "    ax.set_yticks(list(group_centers.values()))\n",
    "    ax.set_yticklabels(list(group_centers.keys()), rotation=0, fontsize=11)\n",
    "\n",
    "    # ------------------------------------------------------------\n",
    "    # Labels\n",
    "    # ------------------------------------------------------------\n",
    "    ax.set_xlabel(\"Predicted pathology\")\n",
    "    ax.set_ylabel(\"Subgroup\")\n",
    "    ax.set_title(f\"{cohort} Subject-level Predicted Probability Heatmap\\n(sorted by descending P(AD))\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "###################### RADAR PLOT #####################\n",
    "    topic_cols = [c for c in inp_df.columns if c.startswith(\"Topic_\")]\n",
    "\n",
    "    groups = inp_df[group_col].unique()\n",
    "    n_groups = len(groups)\n",
    "    n_topics = len(topic_cols)\n",
    "\n",
    "    # ------------------------------------------------------------\n",
    "    # Global max for shared axis\n",
    "    # ------------------------------------------------------------\n",
    "    global_max = (\n",
    "        inp_df\n",
    "        .groupby(group_col)[topic_cols]\n",
    "        .mean()\n",
    "        .values\n",
    "        .max()\n",
    "    )\n",
    "\n",
    "    # ------------------------------------------------------------\n",
    "    # Radar setup\n",
    "    # ------------------------------------------------------------\n",
    "    angles = np.linspace(0, 2 * np.pi, n_topics, endpoint=False)\n",
    "    angles = np.concatenate([angles, [angles[0]]])\n",
    "\n",
    "    fig, axes = plt.subplots(\n",
    "        1, n_groups,\n",
    "        figsize=(4 * n_groups, 4),\n",
    "        subplot_kw=dict(polar=True)\n",
    "    )\n",
    "\n",
    "    if n_groups == 1:\n",
    "        axes = [axes]\n",
    "\n",
    "    # ------------------------------------------------------------\n",
    "    # Plot\n",
    "    # ------------------------------------------------------------\n",
    "    # for ax, grp in zip(axes, groups):\n",
    "    for ax, grp in zip(axes, group_order):\n",
    "        print(ax,grp)\n",
    "\n",
    "        grp_df = inp_df[inp_df[group_col] == grp]\n",
    "        mean_topics = grp_df[topic_cols].mean().values\n",
    "        mean_topics = np.concatenate([mean_topics, [mean_topics[0]]])\n",
    "\n",
    "        ax.plot(angles, mean_topics, linewidth=2)\n",
    "        ax.fill(angles, mean_topics, alpha=0.25)\n",
    "\n",
    "        ax.set_title(grp, pad=20)\n",
    "\n",
    "        ax.set_xticks(angles[:-1])\n",
    "        ax.set_xticklabels(topic_cols, fontsize=9)\n",
    "\n",
    "        ax.set_ylim(0, global_max * 1.1)   # ✅ shared scale\n",
    "        ax.set_yticklabels([])\n",
    "\n",
    "    plt.suptitle(f\"{cohort} Resilience Subgroup Topic Weight Profiles (shared radial scale)\", fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "###################### CORRELATION SCATTER #####################\n",
    "    # -----------------------------\n",
    "    # Example inputs\n",
    "    # -----------------------------\n",
    "    # inp_df: your dataframe\n",
    "    # cols_to_corr: list of columns of probabilities to correlate\n",
    "    # target_col: column to correlate against\n",
    "    cols_to_corr = prob_cols\n",
    "    target_col = scatter_col  # for example\n",
    "\n",
    "    # -----------------------------\n",
    "    # Plotting setup\n",
    "    # -----------------------------\n",
    "    n_cols = 3  # how many subplots per row\n",
    "    n_rows = int(np.ceil(len(cols_to_corr) / n_cols))\n",
    "\n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(5*n_cols, 4*n_rows))\n",
    "    axes = axes.flatten()\n",
    "    palette = sns.color_palette(\"tab10\", n_colors=len(group_order))\n",
    "\n",
    "    group_palette = dict(zip(group_order, palette))\n",
    "\n",
    "    for ax, col in zip(axes, cols_to_corr):\n",
    "        \n",
    "        x = inp_df[col]\n",
    "        y = inp_df[target_col]\n",
    "        \n",
    "        # Compute correlation\n",
    "        r, p = pearsonr(x, y)\n",
    "        \n",
    "        # Scatter plot\n",
    "        sns.scatterplot(\n",
    "            x=x, y=y, hue=inp_df[group_col], palette=group_palette, ax=ax, s=60, alpha=0.8\n",
    "        )\n",
    "        \n",
    "        # Fit line\n",
    "        sns.regplot(x=x, y=y, ax=ax, scatter=False, color='red', ci=None)\n",
    "        \n",
    "        # Annotate r and p\n",
    "        ax.text(0.05, 0.95, f\"r={r:.2f}\\np={p:.3f}\",\n",
    "                transform=ax.transAxes,\n",
    "                verticalalignment='top',\n",
    "                bbox=dict(boxstyle='round,pad=0.3', facecolor='white', alpha=0.7),\n",
    "                fontsize = 13)\n",
    "        \n",
    "        ax.set_xlabel(col)\n",
    "        ax.set_ylabel(target_col)\n",
    "        ax.set_title(f\"{col} vs {target_col}\")\n",
    "        ax.set_xlim([0, 1])\n",
    "        ax.set_ylim([-3, 4])\n",
    "\n",
    "    # Remove empty axes if any\n",
    "    for ax in axes[len(cols_to_corr):]:\n",
    "        ax.remove()\n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "\n",
    "    fig.legend(handles, labels, loc='upper right', title=group_col, bbox_to_anchor=(1.05, 1))\n",
    "    plt.suptitle('NACC')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe52b710",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from data_processor import *\n",
    "from lda_model import LDATopicModel\n",
    "from classifier import TopicClassifier\n",
    "from visualizer import *\n",
    "from brain_visualizer import *\n",
    "\n",
    "data_path = 'C:/Users/WooSikKim/Desktop/Research/projects/co_pathology/scripts/stage_copath/data'\n",
    "\n",
    "inp_df = pd.read_csv(os.path.join(data_path,'train_data/260128_wsev_smc_combined_cn_included.csv'))\n",
    "inp_df = inp_df[inp_df['DX']!='HC'] # EXCLUDE WSEV HC\n",
    "\n",
    "print(inp_df['DX'].value_counts())\n",
    "\n",
    "df_nacc_resilience = pd.read_csv(data_path + '/nacc/NACC_resilience_inference.csv')\n",
    "df_adni4_resilience = pd.read_csv(data_path + '/adni/ADNI4_resilience_inference.csv')\n",
    "# df_nacc_resilience = pd.read_csv('C:/Users/BREIN/Desktop/stage_copath/20260122_NACC_linear_group.csv')\n",
    "\n",
    "df_adni4_resilience = df_adni4_resilience.rename(columns={\"FULL_ID\": \"SUBJ_ID\"})\n",
    "df_nacc_resilience = df_nacc_resilience.rename(columns={\"subject_id\" : \"SUBJ_ID\"})\n",
    "nacc_raw = pd.read_csv(data_path + '/nacc/260120_NACC_VA_TAU_PATH_matched.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f2f644",
   "metadata": {},
   "outputs": [],
   "source": [
    "region_cols = nacc_raw.loc[:, 'VA/2':'VA/2035'].columns\n",
    "# nacc_filtered = nacc_raw[nacc_raw['DX'] != 'Unknown']\n",
    "# nacc_cn = nacc_filtered[nacc_filtered['DX'] == 'CN']\n",
    "\n",
    "\n",
    "## DOWNSAMPLE LARGE DX \n",
    "N = 25\n",
    "dx_col = \"DX\"\n",
    "balanced_parts = []\n",
    "\n",
    "for dx, g in inp_df.groupby(dx_col):\n",
    "    if dx == 'AD':\n",
    "        N=50 ##\n",
    "    elif dx == 'NC':\n",
    "        N=50 ##\n",
    "    else: \n",
    "        N=25\n",
    "    if len(g) > N:\n",
    "        g = g.sample(n=N, replace=False, random_state=42)\n",
    "    balanced_parts.append(g)\n",
    "\n",
    "train_df = pd.concat(balanced_parts).reset_index(drop=True)\n",
    "\n",
    "\n",
    "#### add mci to AD ####\n",
    "# train_df['DX'] = train_df['DX'].replace({'MCI' : 'AD'})\n",
    "\n",
    "#### collapse all non-ad to one DX ##\n",
    "# train_df['DX_new'] = np.where(train_df['DX'].isin(['AD', 'NC']), train_df['DX'], 'non-AD')\n",
    "# print(train_df['DX_new'].value_counts())\n",
    "\n",
    "\n",
    "print(train_df[dx_col].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ae107d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# k = 20\n",
    "k_list = range(4,26,2)\n",
    "perplexities = []\n",
    "cv_acc = []\n",
    "dx_label = 'DX'\n",
    "for k in [8]:\n",
    "    print('K-topics = ', k)\n",
    "    labels = train_df[dx_label].values\n",
    "    ids = train_df[\"SUBJ_ID\"].values\n",
    "\n",
    "    lda = LDATopicModel(n_topics=k, alpha=1/k, beta=1/k)\n",
    "    # lda = LDATopicModel(n_topics=k)\n",
    "    print(lda.alpha, lda.beta)\n",
    "    theta = lda.fit_transform(train_df[region_cols])\n",
    "    classifier = TopicClassifier(n_splits=5)\n",
    "    cv_results = classifier.cross_validate(theta, labels, ids, verbose=False)\n",
    "    classifier.fit(theta, labels)\n",
    "    print(f\"k_topics {k}, CV ACC: {cv_results['accuracy']}\")\n",
    "    print(lda._theta.shape)\n",
    "    \n",
    "    perplexities.append(lda._perplexity)\n",
    "    cv_acc.append(cv_results['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd3b0d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pipeline import CopathologyPipeline\n",
    "pipeline = CopathologyPipeline(\n",
    "    n_topics = 8,\n",
    "    alpha=1/8,\n",
    "    beta=1/8,\n",
    "    output_dir='C:/Users/WooSikKim/Desktop/Research/projects/co_pathology/scripts/stage_copath/results'\n",
    ")\n",
    "results = pipeline.fit(train_df, region_cols=region_cols, standardize=False, subject_col='SUBJ_ID')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddac204b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(k_list, perplexities, marker='o')\n",
    "plt.xlabel(\"Number of topics (K)\")\n",
    "plt.ylabel(\"Perplexity\")\n",
    "plt.title(\"LDA Perplexity vs Number of Topics\")\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(k_list, cv_acc, marker='o')\n",
    "plt.xlabel(\"Number of topics (K)\")\n",
    "plt.ylabel(\"Cross-validated Accuracy\")\n",
    "plt.title(\"Downstream Classification Accuracy vs Number of Topics\")\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "print(k_list[np.argmin(perplexities)], np.min(perplexities))\n",
    "print(k_list[np.argmax(cv_acc)], np.max(cv_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9708f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Internal Visualization\n",
    "dkt_labels = pd.read_csv('C:/Users/WooSikKim/Desktop/Research/projects/co_pathology/scripts/stage_copath/data/dkt_labels.csv')\n",
    "rois = dkt_labels.iloc[0].tolist()\n",
    "\n",
    "visualizer = CopathologyVisualizer(\n",
    "    output_dir=f'C:/Users/WooSikKim/Desktop/Research/projects/co_pathology/scripts/stage_copath/results/train_cn_added/topics_{k}_downsampled'\n",
    ")\n",
    "fig_conf_mat = visualizer.plot_confusion_matrix(\n",
    "    cm=classifier.get_confusion_matrix(),\n",
    "    class_names=classifier._classes,\n",
    "    save=False\n",
    ")\n",
    "\n",
    "fig_top_regions = visualizer.plot_top_regions_per_topic(\n",
    "    topic_patterns = lda.get_topic_patterns(),\n",
    "    region_names=rois,\n",
    "    save=False\n",
    ")\n",
    "\n",
    "radar_plot = visualizer.plot_diagnosis_topic_profiles(\n",
    "    theta=lda._theta,\n",
    "    dx_labels = labels,\n",
    "    save=False\n",
    ")\n",
    "\n",
    "probabilities_heatmap = visualizer.plot_probability_heatmap(\n",
    "    proba_df=classifier.get_cv_results(),\n",
    "    dx_order = [\"NC\", \"AD\", \"DLB\", \"PD\", \"SVAD\", \"bvFTD\", \"nfvPPA\", \"svPPA\"],\n",
    "    save=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d31cc73",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Surface Mapping ##\n",
    "from atlas_vis import DKTAtlas62ROIPlotter\n",
    "plotter_62  = DKTAtlas62ROIPlotter(\n",
    "    cmap='Reds',\n",
    "    clim=(0, 0.1),  \n",
    "    window_size=(1200, 1000),\n",
    "    nan_color='lightgray',\n",
    "    background='white',\n",
    "    template_key='pial'\n",
    ")\n",
    "os.makedirs(f'C:/Users/WooSikKim/Desktop/Research/projects/co_pathology/scripts/stage_copath/results/train_cn_added/topics_{k}_downsampled/topicwise',exist_ok=True)\n",
    "\n",
    "topic_df = pd.DataFrame(\n",
    "    lda.get_topic_patterns().T,\n",
    "    index=region_cols,\n",
    "    columns=[f\"Topic_{k}\" for k in range(k)]\n",
    ")\n",
    "\n",
    "df = topic_df.tail(62).reset_index(drop=True)\n",
    "\n",
    "print(len(df))\n",
    "for col in df.columns: ##################\n",
    "    print(col)\n",
    "    l_values = df.loc[:30,col].to_list()\n",
    "    r_values = df.loc[31:,col].to_list()\n",
    "    print(len(l_values))\n",
    "    print(len(r_values))\n",
    "    print(np.min(l_values+r_values))\n",
    "    print(np.max(l_values+r_values))\n",
    "\n",
    "    plotter_62(l_values, r_values, save_path=f'C:/Users/WooSikKim/Desktop/Research/projects/co_pathology/scripts/stage_copath/results/train_cn_added/topics_{k}_downsampled/topicwise/{col}.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "989694e1",
   "metadata": {},
   "source": [
    "**NACC Inference**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de126fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NACC CN included inference ##\n",
    "nacc_raw = pd.read_csv(os.path.join(data_path, 'nacc/260120_NACC_VA_TAU_PATH_matched.csv'))\n",
    "region_cols = nacc_raw.loc[:, 'VA/2':'VA/2035'].columns\n",
    "pathology_cols = nacc_raw.loc[:, 'NACC_AD':'NACC_svPPA'].columns\n",
    "nacc_filtered = nacc_raw[nacc_raw['DX'] != 'Unknown']\n",
    "\n",
    "nacc_cn = nacc_filtered[nacc_filtered['DX']=='CN']\n",
    "\n",
    "print(nacc_cn.shape)\n",
    "print(nacc_filtered.shape)\n",
    "\n",
    "nacc_prep = DataProcessor(\n",
    "    region_cols=region_cols,\n",
    "    dx_col = 'DX',\n",
    "    subject_col='subject_id'\n",
    ")\n",
    "nacc_prep.fit_baseline(hc_data=nacc_cn)\n",
    "nacc_Z = nacc_prep.compute_atrophy_scores(data=nacc_filtered)\n",
    "# print(type(nacc_Z))\n",
    "\n",
    "nacc_theta = lda.transform(nacc_Z)\n",
    "y_pred = classifier.predict(nacc_theta)\n",
    "y_proba = classifier.predict_proba(nacc_theta)\n",
    "\n",
    "nacc_results = pd.DataFrame(nacc_theta, columns=[f\"Topic_{k}\" for k in range(lda.n_topics)])\n",
    "print(nacc_results.shape)\n",
    "subj_col = nacc_prep.subject_col\n",
    "if subj_col in nacc_filtered.columns:\n",
    "    nacc_results.insert(0, \"SUBJ_ID\", nacc_filtered[subj_col].values)\n",
    "\n",
    "nacc_results['pred_DX'] = y_pred\n",
    "for i, dx in enumerate(classifier.classes):\n",
    "    nacc_results[f\"P({dx})\"] = y_proba[:,i]\n",
    "\n",
    "nacc_results = nacc_results.merge(\n",
    "    nacc_raw[[\"subject_id\", \"DX\", 'NACC_AD', 'NACC_PD', 'NACC_VD', 'NACC_LBD', 'NACC_SVAD', 'NACC_PCA', 'NACC_bvFTD']],\n",
    "    left_on=\"SUBJ_ID\",\n",
    "    right_on=\"subject_id\",\n",
    "    how=\"left\"\n",
    ")\n",
    "nacc_results = nacc_results.drop(columns=[\"subject_id\"])\n",
    "\n",
    "print(nacc_results['DX'].value_counts())\n",
    "nacc_results_cn = nacc_results[nacc_results['DX']=='CN']\n",
    "nacc_results_imci = nacc_results[nacc_results['DX']=='IMCI']\n",
    "nacc_results_mci = nacc_results[nacc_results['DX']=='MCI']\n",
    "nacc_results_ad = nacc_results[nacc_results['DX']=='AD']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db94f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "status_cols = ['NACC_AD', 'NACC_PD', 'NACC_VD', 'NACC_LBD', 'NACC_PCA']  # example\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Prepare data: proportion of positives and negatives\n",
    "# -----------------------------\n",
    "prop_nacc_results_list = []\n",
    "\n",
    "for col in status_cols:\n",
    "    # Compute proportion of positives per group\n",
    "    pos = nacc_results.groupby(group_col)[col].mean()\n",
    "    neg = 1 - pos  # proportion of negatives\n",
    "    \n",
    "    temp_nacc_results = pd.DataFrame({\n",
    "        'Group': pos.index,\n",
    "        'Positive': pos.values,\n",
    "        'Negative': neg.values,\n",
    "        'Condition': col\n",
    "    })\n",
    "    prop_nacc_results_list.append(temp_nacc_results)\n",
    "\n",
    "# Combine all conditions for plotting\n",
    "plot_nacc_results = pd.concat(prop_nacc_results_list)\n",
    "\n",
    "# -----------------------------\n",
    "# Plot stacked barplot\n",
    "# -----------------------------\n",
    "conditions = plot_nacc_results['Condition'].unique()\n",
    "n_cols = 2\n",
    "n_rows = (len(conditions) + 1) // n_cols\n",
    "\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(6*n_cols, 5*n_rows))\n",
    "axes = axes.flatten()\n",
    "\n",
    "colors = {'Positive':'blue', 'Negative':'red'}\n",
    "\n",
    "for ax, cond in zip(axes, conditions):\n",
    "    nacc_results_cond = plot_nacc_results[plot_nacc_results['Condition'] == cond].set_index('Group')\n",
    "    nacc_results_cond[['Negative','Positive']].plot(\n",
    "        kind='bar',\n",
    "        stacked=True,\n",
    "        ax=ax,\n",
    "        color=[colors['Negative'], colors['Positive']],\n",
    "        legend=False\n",
    "    )\n",
    "    ax.set_ylabel('Proportion')\n",
    "    ax.set_title(cond)\n",
    "    ax.set_ylim(0,1)\n",
    "\n",
    "# Single legend for figure\n",
    "handles = [plt.Rectangle((0,0),1,1,color=colors[c]) for c in colors]\n",
    "fig.legend(handles, colors.keys(), loc='upper right', title='Status')\n",
    "\n",
    "# Remove unused axes\n",
    "for ax in axes[len(conditions):]:\n",
    "    ax.remove()\n",
    "plt.suptitle('NACC Pathology Positivity Proportions')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c12d67c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prob_cols = nacc_results.loc[:,'P(AD)':'P(svPPA)'].columns\n",
    "prob_cols = ['P(NC)', 'P(AD)', 'P(PD)', 'P(DLB)', 'P(SVAD)', 'P(bvFTD)', 'P(nfvPPA)', 'P(svPPA)']\n",
    "group_col = 'TN_group'\n",
    "# group_col = 'linear_group'\n",
    "group_order = ['Resilient', 'Canonical', 'Vulnerable']\n",
    "plot_df = nacc_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e61c3ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_means = (\n",
    "    plot_df\n",
    "    .groupby(group_col)[prob_cols]\n",
    "    .mean()\n",
    "    .reindex(group_order)\n",
    ")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Plot heatmap\n",
    "# ------------------------------------------------------------\n",
    "plt.figure(figsize=(8, 5))\n",
    "\n",
    "sns.heatmap(\n",
    "    group_means,\n",
    "    cmap=\"Reds\",\n",
    "    annot=True,\n",
    "    fmt=\".2f\",\n",
    "    linewidths=0.5,\n",
    "    vmin=0,\n",
    "    vmax=1,\n",
    "    cbar_kws={\"label\": \"Mean predicted probability\"}\n",
    ")\n",
    "\n",
    "plt.xlabel(\"Predicted pathology\")\n",
    "plt.ylabel(\"Subgroup\")\n",
    "plt.title(\"NACC Group-wise Mean Predicted Probability Distribution\")\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66f0ed16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------\n",
    "# Sort: group first, then descending P(AD)\n",
    "# ------------------------------------------------------------\n",
    "plot_df[group_col] = pd.Categorical(\n",
    "    plot_df[group_col],\n",
    "    categories=group_order,\n",
    "    ordered=True\n",
    ")\n",
    "\n",
    "nacc_sorted = (\n",
    "    plot_df\n",
    "    .sort_values([group_col, \"P(AD)\"], ascending=[True, False])\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "\n",
    "heatmap_data = nacc_sorted[prob_cols]\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Compute group positions for y-axis labels\n",
    "# ------------------------------------------------------------\n",
    "group_counts = (\n",
    "    nacc_sorted[group_col]\n",
    "    .value_counts()\n",
    "    .reindex(group_order)\n",
    ")\n",
    "\n",
    "\n",
    "group_centers = {}\n",
    "start = 0\n",
    "\n",
    "for grp, count in group_counts.items():\n",
    "    center = start + count / 2\n",
    "    group_centers[grp] = center\n",
    "    start += count\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Plot\n",
    "# ------------------------------------------------------------\n",
    "plt.figure(figsize=(10, 10))\n",
    "\n",
    "ax = sns.heatmap(\n",
    "    heatmap_data,\n",
    "    cmap=\"Reds\",\n",
    "    vmin=0,\n",
    "    vmax=1,\n",
    "    yticklabels=False,\n",
    "    cbar_kws={\"label\": \"Predicted probability\"}\n",
    ")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Horizontal lines between groups\n",
    "# ------------------------------------------------------------\n",
    "cum_sizes = np.cumsum(group_counts.values)\n",
    "\n",
    "for y in cum_sizes[:-1]:\n",
    "    ax.hlines(y, *ax.get_xlim(), colors=\"black\", linewidth=1.5)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# TN subgroup labels on y-axis\n",
    "# ------------------------------------------------------------\n",
    "ax.set_yticks(list(group_centers.values()))\n",
    "ax.set_yticklabels(list(group_centers.keys()), rotation=0, fontsize=11)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Labels\n",
    "# ------------------------------------------------------------\n",
    "ax.set_xlabel(\"Predicted pathology\")\n",
    "ax.set_ylabel(\"Subgroup\")\n",
    "ax.set_title(\"Subject-level Predicted Probability Heatmap\\n(sorted by descending P(AD))\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a121d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_cols = [c for c in plot_df.columns if c.startswith(\"Topic_\")]\n",
    "\n",
    "groups = plot_df[group_col].unique()\n",
    "n_groups = len(groups)\n",
    "n_topics = len(topic_cols)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Global max for shared axis\n",
    "# ------------------------------------------------------------\n",
    "global_max = (\n",
    "    plot_df\n",
    "    .groupby(group_col)[topic_cols]\n",
    "    .mean()\n",
    "    .values\n",
    "    .max()\n",
    ")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Radar setup\n",
    "# ------------------------------------------------------------\n",
    "angles = np.linspace(0, 2 * np.pi, n_topics, endpoint=False)\n",
    "angles = np.concatenate([angles, [angles[0]]])\n",
    "\n",
    "fig, axes = plt.subplots(\n",
    "    1, n_groups,\n",
    "    figsize=(4 * n_groups, 4),\n",
    "    subplot_kw=dict(polar=True)\n",
    ")\n",
    "\n",
    "if n_groups == 1:\n",
    "    axes = [axes]\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Plot\n",
    "# ------------------------------------------------------------\n",
    "# for ax, grp in zip(axes, groups):\n",
    "for ax, grp in zip(axes, ['Vulnerable', 'Canonical', 'Resilient']):\n",
    "\n",
    "    grp_df = plot_df[plot_df[group_col] == grp]\n",
    "    mean_topics = grp_df[topic_cols].mean().values\n",
    "    mean_topics = np.concatenate([mean_topics, [mean_topics[0]]])\n",
    "\n",
    "    ax.plot(angles, mean_topics, linewidth=2)\n",
    "    ax.fill(angles, mean_topics, alpha=0.25)\n",
    "\n",
    "    ax.set_title(grp, pad=20)\n",
    "\n",
    "    ax.set_xticks(angles[:-1])\n",
    "    ax.set_xticklabels(topic_cols, fontsize=9)\n",
    "\n",
    "    ax.set_ylim(0, global_max * 1.1)   # ✅ shared scale\n",
    "    ax.set_yticklabels([])\n",
    "\n",
    "plt.suptitle(\"Resilience Subgroup Topic Weight Profiles (shared radial scale)\", fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c3a2e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Correlation Subplots ##\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import pearsonr  # or spearmanr if you prefer\n",
    "import numpy as np\n",
    "\n",
    "# -----------------------------\n",
    "# Example inputs\n",
    "# -----------------------------\n",
    "# plot_df: your dataframe\n",
    "# cols_to_corr: list of columns of probabilities to correlate\n",
    "# target_col: column to correlate against\n",
    "cols_to_corr = prob_cols\n",
    "target_col = 'standardized_residual'  # for example\n",
    "\n",
    "# -----------------------------\n",
    "# Plotting setup\n",
    "# -----------------------------\n",
    "n_cols = 3  # how many subplots per row\n",
    "n_rows = int(np.ceil(len(cols_to_corr) / n_cols))\n",
    "\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(5*n_cols, 4*n_rows))\n",
    "axes = axes.flatten()\n",
    "palette = sns.color_palette(\"tab10\", n_colors=len(group_order))\n",
    "\n",
    "group_palette = dict(zip(group_order, palette))\n",
    "\n",
    "for ax, col in zip(axes, cols_to_corr):\n",
    "    \n",
    "    x = plot_df[col]\n",
    "    y = plot_df[target_col]\n",
    "    \n",
    "    # Compute correlation\n",
    "    r, p = pearsonr(x, y)\n",
    "    \n",
    "    # Scatter plot\n",
    "    sns.scatterplot(\n",
    "        x=x, y=y, hue=plot_df[group_col], palette=group_palette, ax=ax, s=60, alpha=0.8\n",
    "    )\n",
    "    \n",
    "    # Fit line\n",
    "    sns.regplot(x=x, y=y, ax=ax, scatter=False, color='red', ci=None)\n",
    "    \n",
    "    # Annotate r and p\n",
    "    ax.text(0.05, 0.95, f\"r={r:.2f}\\np={p:.3f}\",\n",
    "            transform=ax.transAxes,\n",
    "            verticalalignment='top',\n",
    "            bbox=dict(boxstyle='round,pad=0.3', facecolor='white', alpha=0.7),\n",
    "            fontsize = 13)\n",
    "    \n",
    "    ax.set_xlabel(col)\n",
    "    ax.set_ylabel(target_col)\n",
    "    ax.set_title(f\"{col} vs {target_col}\")\n",
    "    ax.set_xlim([0, 1])\n",
    "    ax.set_ylim([-3, 4])\n",
    "\n",
    "# Remove empty axes if any\n",
    "for ax in axes[len(cols_to_corr):]:\n",
    "    ax.remove()\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "\n",
    "fig.legend(handles, labels, loc='upper right', title=group_col, bbox_to_anchor=(1.05, 1))\n",
    "plt.suptitle('NACC')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a681aaa",
   "metadata": {},
   "source": [
    "**STAGE MODEL INFERENCE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f02f30e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "stage_input_df = pd.read_csv('C:/Users/WooSikKim/Desktop/Research/projects/co_pathology/scripts/stage_copath/data/stage_data/All.diff.260115.allvolume.NDadded.cohortwise.csv')\n",
    "print(stage_input_df.shape)\n",
    "stage_region_cols = stage_input_df.loc[:, 'NDVA/2':'NDVA/2035'].columns\n",
    "stage_input_df = stage_input_df.dropna(subset=stage_region_cols)\n",
    "\n",
    "# stage_Z = stage_input_df[['FULL_ID', 'COHORT'] +  stage_region_cols] \n",
    "stage_Z = stage_input_df[stage_region_cols].values\n",
    "stage_Z[stage_Z<0] = 0\n",
    "print(stage_Z.shape)\n",
    "stage_theta = lda.fit_transform(stage_Z)\n",
    "print(stage_theta.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5784b9b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "stage_results = pd.DataFrame(stage_theta, columns=[f\"Topic_{k}\" for k in range(lda.n_topics)])\n",
    "# stage_results.insert(\n",
    "#     0,\n",
    "#     \"SUBJ_ID\",\n",
    "#     stage_input_df[\"FULL_ID\"].values,\n",
    "# )\n",
    "\n",
    "stage_concat = pd.concat(\n",
    "    [stage_input_df.reset_index(drop=True),\n",
    "     stage_results.reset_index(drop=True)],\n",
    "    axis=1\n",
    ")\n",
    "stage_concat.to_csv('C:/Users/WooSikKim/Desktop/Research/projects/co_pathology/scripts/stage_copath/data/stage_data/All.diff.260115.allvolume.NDadded.cohortwise_lda_topic_added_k_8_param.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f66ee069",
   "metadata": {},
   "source": [
    "**NACC STAGE INFERENCE VULNERABILITY**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b606bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NACC CN included inference ##\n",
    "nacc_aa_raw = pd.read_csv('C:/Users/WooSikKim/Desktop/Research/projects/co_pathology/scripts/stage_copath/data/nacc/260203_STAGE_PRED_GT_NACC.csv')\n",
    "nacc_aa_raw = nacc_aa_raw[nacc_aa_raw['DX']!='Unknown']\n",
    "order = {'low': 0, 'mid': 1, 'high': 2}\n",
    "gt_num = nacc_aa_raw['TAU/stage_aa_gt'].map(order)\n",
    "pred_num = nacc_aa_raw['TAU/stage_aa_pred'].map(order)\n",
    "nacc_aa_raw['TAU/stage_res_subgroup'] = np.select(\n",
    "    [\n",
    "        pred_num > gt_num,   # predicted worse than GT\n",
    "        pred_num == gt_num,  # correct\n",
    "        pred_num < gt_num    # predicted better than GT\n",
    "    ],\n",
    "    [\n",
    "        'vulnerable',\n",
    "        'canonical',\n",
    "        'resilient'\n",
    "    ],\n",
    "    default=np.nan\n",
    ")\n",
    "region_cols = nacc_aa_raw.loc[:, 'VA/2':'VA/2035'].columns\n",
    "nacc_aa_cn = nacc_aa_raw[nacc_aa_raw['DX']=='CN']\n",
    "\n",
    "print(nacc_aa_cn.shape)\n",
    "print(nacc_aa_raw.shape)\n",
    "\n",
    "nacc_aa_prep = DataProcessor(\n",
    "    region_cols=region_cols,\n",
    "    dx_col = 'DX',\n",
    "    subject_col='subject_id'\n",
    ")\n",
    "nacc_aa_prep.fit_baseline(hc_data=nacc_aa_cn)\n",
    "nacc_Z = nacc_aa_prep.compute_atrophy_scores(data=nacc_aa_raw)\n",
    "nacc_theta = lda.transform(nacc_Z)\n",
    "y_pred = classifier.predict(nacc_theta)\n",
    "y_proba = classifier.predict_proba(nacc_theta)\n",
    "\n",
    "nacc_results = pd.DataFrame(nacc_theta, columns=[f\"Topic_{k}\" for k in range(lda.n_topics)])\n",
    "print(nacc_results.shape)\n",
    "subj_col = nacc_aa_prep.subject_col\n",
    "if subj_col in nacc_aa_raw.columns:\n",
    "    nacc_results.insert(0, \"SUBJ_ID\", nacc_aa_raw[subj_col].values)\n",
    "    \n",
    "nacc_results['pred_DX'] = y_pred\n",
    "for i, dx in enumerate(classifier.classes):\n",
    "    nacc_results[f\"P({dx})\"] = y_proba[:,i]\n",
    "\n",
    "nacc_results = nacc_results.merge(\n",
    "    nacc_aa_raw[[\"subject_id\", \"DX\", 'TAU/NEO_SUVR', 'TAU/MTL_SUVR', 'TAU/stage_aa_gt', 'TAU/stage_aa_pred', 'TAU/stage_res_subgroup']],\n",
    "    left_on=\"SUBJ_ID\",\n",
    "    right_on=\"subject_id\",\n",
    "    how=\"left\"\n",
    ")\n",
    "nacc_results = nacc_results.drop(columns=[\"subject_id\"])\n",
    "\n",
    "print(nacc_results['DX'].value_counts())\n",
    "nacc_results_cn = nacc_results[nacc_results['DX']=='CN']\n",
    "nacc_results_mci_ad = nacc_results[nacc_results['DX']!='CN']\n",
    "nacc_results_imci = nacc_results[nacc_results['DX']=='IMCI']\n",
    "nacc_results_mci = nacc_results[nacc_results['DX']=='MCI']\n",
    "nacc_results_ad = nacc_results[nacc_results['DX']=='AD']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d583e393",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prob_cols = nacc_results_mci.loc[:,'P(AD)':'P(svPPA)'].columns\n",
    "prob_cols = ['P(NC)', 'P(AD)', 'P(PD)', 'P(DLB)', 'P(SVAD)', 'P(bvFTD)', 'P(nfvPPA)', 'P(svPPA)']\n",
    "group_col = 'TAU/stage_res_subgroup'\n",
    "\n",
    "plot_df = nacc_results\n",
    "group_order = ['resilient', 'canonical', 'vulnerable']\n",
    "\n",
    "# plot_df = plot_df[plot_df[group_col]!='canonical']\n",
    "# group_order = ['resilient', 'vulnerable']\n",
    "\n",
    "print(plot_df[group_col].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b691925",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(plot_df.shape)\n",
    "plot_df = nacc_results\n",
    "non_ad_cols = ['P(PD)', 'P(DLB)', 'P(SVAD)', 'P(bvFTD)', 'P(nfvPPA)', 'P(svPPA)']\n",
    "plot_df['P(non_AD)'] = plot_df[non_ad_cols].sum(axis=1)\n",
    "\n",
    "# plot_df = plot_df[plot_df[group_col]!='canonical']\n",
    "# temp_order = ['resilient', 'vulnerable']\n",
    "\n",
    "test_cols = ['P(NC)', 'P(AD)', 'P(non_AD)']\n",
    "\n",
    "resilient_subgroup_visualization(\n",
    "    inp_df=plot_df, \n",
    "    prob_cols=test_cols,\n",
    "    group_col=group_col,\n",
    "    group_order=group_order,\n",
    "    cohort='NACC',\n",
    "    scatter_col='TAU/NEO_SUVR'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d214516",
   "metadata": {},
   "outputs": [],
   "source": [
    "resilient_subgroup_visualization(\n",
    "    inp_df=plot_df,\n",
    "    prob_cols=prob_cols,\n",
    "    group_col=group_col,\n",
    "    group_order=group_order,\n",
    "    cohort='NACC',\n",
    "    scatter_col='TAU/NEO_SUVR'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac4665a4",
   "metadata": {},
   "source": [
    "**ADNI3 STAGE INFERENCE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cab02ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "adni3_raw = pd.read_csv('C:/Users/WooSikKim/Desktop/Research/projects/co_pathology/scripts/stage_copath/data/stage_data/ptau_volume_model/ADNI_3.csv')\n",
    "region_cols = adni3_raw.loc[:, 'VA/2':'VA/2035'].columns\n",
    "adni3_raw['TAU/stage_aa_gt'] = (\n",
    "    adni3_raw[['tau_stage_aa/low', 'tau_stage_aa/mid', 'tau_stage_aa/high']]\n",
    "    .idxmax(axis=1)\n",
    "    .str.replace('tau_stage_aa/', '', regex=False)\n",
    ")\n",
    "adni3_raw['TAU/stage_aa_pred'] = (\n",
    "    adni3_raw[['pred_tau_stage_aa/low', 'pred_tau_stage_aa/mid', 'pred_tau_stage_aa/high']]\n",
    "    .idxmax(axis=1)\n",
    "    .str.replace('pred_tau_stage_aa/', '', regex=False)\n",
    ")\n",
    "adni3_raw = adni3_raw.dropna(subset='TAU/stage_aa_gt')\n",
    "order = {'low': 0, 'mid': 1, 'high': 2}\n",
    "gt_num = adni3_raw['TAU/stage_aa_gt'].map(order)\n",
    "pred_num = adni3_raw['TAU/stage_aa_pred'].map(order)\n",
    "adni3_raw['TAU/stage_res_subgroup'] = np.select(\n",
    "    [\n",
    "        pred_num > gt_num,   # predicted worse than GT\n",
    "        pred_num == gt_num,  # correct\n",
    "        pred_num < gt_num    # predicted better than GT\n",
    "    ],\n",
    "    [\n",
    "        'vulnerable',\n",
    "        'canonical',\n",
    "        'resilient'\n",
    "    ],\n",
    "    default=np.nan\n",
    ")\n",
    "adni3_cn = adni3_raw[adni3_raw['DX']=='CN']\n",
    "print(adni3_raw['TAU/stage_res_subgroup'].value_counts())\n",
    "\n",
    "\n",
    "adni3_aa_prep = DataProcessor(\n",
    "    region_cols=region_cols,\n",
    "    dx_col = 'DX',\n",
    "    subject_col='FULL_ID'\n",
    ")\n",
    "adni3_aa_prep.fit_baseline(hc_data=adni3_cn)\n",
    "adni3_Z = adni3_aa_prep.compute_atrophy_scores(data=adni3_raw)\n",
    "adni3_theta = lda.transform(adni3_Z)\n",
    "y_pred = classifier.predict(adni3_theta)\n",
    "y_proba = classifier.predict_proba(adni3_theta)\n",
    "\n",
    "adni3_results = pd.DataFrame(adni3_theta, columns=[f\"Topic_{k}\" for k in range(lda.n_topics)])\n",
    "print(adni3_results.shape)\n",
    "subj_col = adni3_aa_prep.subject_col\n",
    "if subj_col in adni3_raw.columns:\n",
    "    adni3_results.insert(0, \"SUBJ_ID\", adni3_raw[subj_col].values)\n",
    "    \n",
    "adni3_results['pred_DX'] = y_pred\n",
    "for i, dx in enumerate(classifier.classes):\n",
    "    adni3_results[f\"P({dx})\"] = y_proba[:,i]\n",
    "\n",
    "adni3_results = adni3_results.merge(\n",
    "    adni3_raw[[\"FULL_ID\", \"DX\", 'tau_z/Neo','TAU/stage_aa_gt', 'TAU/stage_aa_pred', 'TAU/stage_res_subgroup']],\n",
    "    left_on=\"SUBJ_ID\",\n",
    "    right_on=\"FULL_ID\",\n",
    "    how=\"left\"\n",
    ")\n",
    "adni3_results = adni3_results.drop(columns=[\"FULL_ID\"])\n",
    "\n",
    "print(adni3_results['DX'].value_counts())\n",
    "adni3_results_cn = adni3_results[adni3_results['DX']=='CN']\n",
    "adni3_results_mci = adni3_results[adni3_results['DX']=='MCI']\n",
    "adni3_results_ad = adni3_results[adni3_results['DX']=='Dementia']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c379c813",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prob_cols = adni3_results_mci.loc[:,'P(AD)':'P(svPPA)'].columns\n",
    "prob_cols = ['P(NC)', 'P(AD)', 'P(PD)', 'P(DLB)', 'P(SVAD)', 'P(bvFTD)', 'P(nfvPPA)', 'P(svPPA)']\n",
    "group_col = 'TAU/stage_res_subgroup'\n",
    "\n",
    "plot_df = adni3_results_ad\n",
    "group_order = ['resilient', 'canonical', 'vulnerable']\n",
    "\n",
    "# plot_df = plot_df[plot_df[group_col]!='canonical']\n",
    "# group_order = ['resilient', 'vulnerable']\n",
    "\n",
    "print(plot_df[group_col].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a9d5c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "resilient_subgroup_visualization(\n",
    "    inp_df=plot_df,\n",
    "    prob_cols=prob_cols,\n",
    "    group_col=group_col,\n",
    "    group_order=group_order,\n",
    "    cohort='ADNI3',\n",
    "    scatter_col='tau_z/Neo'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "712358a9",
   "metadata": {},
   "source": [
    "**ADNI4 STAGE INFERENCE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74a21a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "adni4_raw = pd.read_csv('C:/Users/WooSikKim/Desktop/Research/projects/co_pathology/scripts/stage_copath/data/stage_data/ptau_volume_model/ADNI4_3.csv')\n",
    "region_cols = adni4_raw.loc[:, 'VA/2':'VA/2035'].columns\n",
    "adni4_raw['TAU/stage_aa_gt'] = (\n",
    "    adni4_raw[['tau_stage_aa/low', 'tau_stage_aa/mid', 'tau_stage_aa/high']]\n",
    "    .idxmax(axis=1)\n",
    "    .str.replace('tau_stage_aa/', '', regex=False)\n",
    ")\n",
    "adni4_raw['TAU/stage_aa_pred'] = (\n",
    "    adni4_raw[['pred_tau_stage_aa/low', 'pred_tau_stage_aa/mid', 'pred_tau_stage_aa/high']]\n",
    "    .idxmax(axis=1)\n",
    "    .str.replace('pred_tau_stage_aa/', '', regex=False)\n",
    ")\n",
    "adni4_raw = adni4_raw.dropna(subset='TAU/stage_aa_gt')\n",
    "order = {'low': 0, 'mid': 1, 'high': 2}\n",
    "gt_num = adni4_raw['TAU/stage_aa_gt'].map(order)\n",
    "pred_num = adni4_raw['TAU/stage_aa_pred'].map(order)\n",
    "adni4_raw['TAU/stage_res_subgroup'] = np.select(\n",
    "    [\n",
    "        pred_num > gt_num,   # predicted worse than GT\n",
    "        pred_num == gt_num,  # correct\n",
    "        pred_num < gt_num    # predicted better than GT\n",
    "    ],\n",
    "    [\n",
    "        'vulnerable',\n",
    "        'canonical',\n",
    "        'resilient'\n",
    "    ],\n",
    "    default=np.nan\n",
    ")\n",
    "adni4_cn = adni4_raw[adni4_raw['DX']=='CN']\n",
    "print(adni4_raw['TAU/stage_res_subgroup'].value_counts())\n",
    "\n",
    "\n",
    "adni4_aa_prep = DataProcessor(\n",
    "    region_cols=region_cols,\n",
    "    dx_col = 'DX',\n",
    "    subject_col='FULL_ID'\n",
    ")\n",
    "adni4_aa_prep.fit_baseline(hc_data=adni4_cn)\n",
    "adni4_Z = adni4_aa_prep.compute_atrophy_scores(data=adni4_raw)\n",
    "adni4_theta = lda.transform(adni4_Z)\n",
    "y_pred = classifier.predict(adni4_theta)\n",
    "y_proba = classifier.predict_proba(adni4_theta)\n",
    "\n",
    "adni4_results = pd.DataFrame(adni4_theta, columns=[f\"Topic_{k}\" for k in range(lda.n_topics)])\n",
    "print(adni4_results.shape)\n",
    "subj_col = adni4_aa_prep.subject_col\n",
    "if subj_col in adni4_raw.columns:\n",
    "    adni4_results.insert(0, \"SUBJ_ID\", adni4_raw[subj_col].values)\n",
    "    \n",
    "adni4_results['pred_DX'] = y_pred\n",
    "for i, dx in enumerate(classifier.classes):\n",
    "    adni4_results[f\"P({dx})\"] = y_proba[:,i]\n",
    "\n",
    "adni4_results = adni4_results.merge(\n",
    "    adni4_raw[[\"FULL_ID\", \"DX\", 'tau_z/Neo','TAU/stage_aa_gt', 'TAU/stage_aa_pred', 'TAU/stage_res_subgroup']],\n",
    "    left_on=\"SUBJ_ID\",\n",
    "    right_on=\"FULL_ID\",\n",
    "    how=\"left\"\n",
    ")\n",
    "adni4_results = adni4_results.drop(columns=[\"FULL_ID\"])\n",
    "\n",
    "print(adni4_results['DX'].value_counts())\n",
    "adni4_results_cn = adni4_results[adni4_results['DX']=='CN']\n",
    "adni4_results_mci = adni4_results[adni4_results['DX']=='MCI']\n",
    "adni4_results_ad = adni4_results[adni4_results['DX']=='AD']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e483105",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prob_cols =adni4_results_mci.loc[:,'P(AD)':'P(svPPA)'].columns\n",
    "prob_cols = ['P(NC)', 'P(AD)', 'P(PD)', 'P(DLB)', 'P(SVAD)', 'P(bvFTD)', 'P(nfvPPA)', 'P(svPPA)']\n",
    "group_col = 'TAU/stage_res_subgroup'\n",
    "\n",
    "plot_df =adni4_results_ad\n",
    "group_order = ['resilient', 'canonical', 'vulnerable']\n",
    "\n",
    "# plot_df = plot_df[plot_df[group_col]!='canonical']\n",
    "# group_order = ['resilient', 'vulnerable']\n",
    "\n",
    "print(plot_df[group_col].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1fd8143",
   "metadata": {},
   "outputs": [],
   "source": [
    "resilient_subgroup_visualization(\n",
    "    inp_df=plot_df,\n",
    "    prob_cols=prob_cols,\n",
    "    group_col=group_col, \n",
    "    group_order=group_order,\n",
    "    cohort='ADNI4',\n",
    "    scatter_col='tau_z/Neo'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90647ff5",
   "metadata": {},
   "source": [
    "**A4 INFERENCE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cbfd50f",
   "metadata": {},
   "outputs": [],
   "source": [
    "a4_raw = pd.read_csv('C:/Users/WooSikKim/Desktop/Research/projects/co_pathology/scripts/stage_copath/data/stage_data/A4/A4_external_260203.add_tau_p.va_area_lobe.csv')\n",
    "a4_stage_inf = pd.read_csv('C:/Users/WooSikKim/Desktop/Research/projects/co_pathology/scripts/stage_copath/data/stage_data/A4/inferenced.csv')\n",
    "region_cols = a4_raw.loc[:, 'VA_z/2':'VA_z/2035'].columns\n",
    "\n",
    "a4_inp_df = a4_stage_inf.merge(a4_raw, on='FULL_ID', how='left', suffixes=('','_drop'))\n",
    "a4_inp_df = a4_inp_df.dropna(subset=region_cols)\n",
    "\n",
    "a4_inp_df['TAU/stage_aa_gt'] = (\n",
    "    a4_inp_df[['tau_stage_aa/low', 'tau_stage_aa/mid', 'tau_stage_aa/high']]\n",
    "    .idxmax(axis=1)\n",
    "    .str.replace('tau_stage_aa/', '', regex=False)\n",
    ")\n",
    "a4_inp_df['TAU/stage_aa_pred'] = (\n",
    "    a4_inp_df[['pred_tau_stage_aa/low', 'pred_tau_stage_aa/mid', 'pred_tau_stage_aa/high']]\n",
    "    .idxmax(axis=1)\n",
    "    .str.replace('pred_tau_stage_aa/', '', regex=False)\n",
    ")\n",
    "a4_inp_df = a4_inp_df.dropna(subset='TAU/stage_aa_gt')\n",
    "order = {'low': 0, 'mid': 1, 'high': 2}\n",
    "gt_num = a4_inp_df['TAU/stage_aa_gt'].map(order)\n",
    "pred_num = a4_inp_df['TAU/stage_aa_pred'].map(order)\n",
    "a4_inp_df['TAU/stage_res_subgroup'] = np.select(\n",
    "    [\n",
    "        pred_num > gt_num,   # predicted worse than GT\n",
    "        pred_num == gt_num,  # correct\n",
    "        pred_num < gt_num    # predicted better than GT\n",
    "    ],\n",
    "    [\n",
    "        'vulnerable',\n",
    "        'canonical',\n",
    "        'resilient'\n",
    "    ],\n",
    "    default=np.nan\n",
    ")\n",
    "\n",
    "a4_Z = a4_inp_df[region_cols].values\n",
    "a4_Z = -a4_Z\n",
    "a4_Z[a4_Z<0] = 0\n",
    "\n",
    "print(a4_Z.shape)\n",
    "a4_theta = lda.fit_transform(a4_Z)\n",
    "# print(stage_theta.shape)\n",
    "y_pred = classifier.predict(a4_theta)\n",
    "y_proba = classifier.predict_proba(a4_theta)\n",
    "\n",
    "\n",
    "a4_results = pd.DataFrame(a4_theta, columns=[f\"Topic_{k}\" for k in range(lda.n_topics)])\n",
    "print(a4_results.shape)\n",
    "if \"FULL_ID\" in a4_inp_df.columns:\n",
    "    a4_results.insert(0, \"SUBJ_ID\", a4_inp_df['FULL_ID'].values)\n",
    "    \n",
    "a4_results['pred_DX'] = y_pred\n",
    "for i, dx in enumerate(classifier.classes):\n",
    "    a4_results[f\"P({dx})\"] = y_proba[:,i]\n",
    "\n",
    "a4_results = a4_results.merge(\n",
    "    a4_inp_df[[\"FULL_ID\", \"DX\", 'TAU/stage_aa_gt', 'TAU/stage_aa_pred', 'TAU/stage_res_subgroup']],\n",
    "    left_on=\"SUBJ_ID\",\n",
    "    right_on=\"FULL_ID\",\n",
    "    how=\"left\"\n",
    ")\n",
    "a4_results = a4_results.drop(columns=[\"FULL_ID\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3a95a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prob_cols =a4_results_mci.loc[:,'P(AD)':'P(svPPA)'].columns\n",
    "prob_cols = ['P(NC)', 'P(AD)', 'P(PD)', 'P(DLB)', 'P(SVAD)', 'P(bvFTD)', 'P(nfvPPA)', 'P(svPPA)']\n",
    "group_col = 'TAU/stage_res_subgroup'\n",
    "\n",
    "plot_df = a4_results\n",
    "group_order = ['resilient', 'canonical', 'vulnerable']\n",
    "\n",
    "# plot_df = plot_df[plot_df[group_col]!='canonical']\n",
    "# group_order = ['resilient', 'vulnerable']\n",
    "\n",
    "print(plot_df[group_col].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9703ab5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "resilient_subgroup_visualization(\n",
    "    inp_df=plot_df,\n",
    "    prob_cols=prob_cols,\n",
    "    group_col=group_col, \n",
    "    group_order=group_order,\n",
    "    cohort='A4',\n",
    "    scatter_col=None\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "405be55d",
   "metadata": {},
   "source": [
    "**NACC ALL STAGE INFERENCE DATA - ALL**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccecf533",
   "metadata": {},
   "outputs": [],
   "source": [
    "nacc_stage = pd.read_csv('C:/Users/WooSikKim/Desktop/Research/projects/co_pathology/scripts/stage_copath/data/nacc/260203_STAGE_NACC_inference.csv')\n",
    "nacc_gt = pd.read_csv('C:/Users/WooSikKim/Desktop/Research/projects/co_pathology/scripts/stage_copath/data/nacc/260206_STAGE_PRED_GT_NACC.csv')\n",
    "d2 = pd.read_csv('C:/Users/WooSikKim/Desktop/Research/projects/co_pathology/scripts/stage_copath/data/nacc/260206_STAGE_PRED_GT_NACC.csv')\n",
    "nacc_gt = nacc_gt.dropna(subset='TAU/SCANDATE')\n",
    "tau_col = nacc_gt.loc[:,'TAU/MTL_SUVR':'TAU/stage_aa_gt'].columns.to_list()\n",
    "nacc_gt = nacc_gt[['FULL_ID']+tau_col]\n",
    "nacc_gt = nacc_gt.rename(columns={\n",
    "    'TAU/MTL_SUVR': 'tau/MTL', 'TAU/NEO_SUVR': 'tau_z/Neo', 'TAU/MTL_Z' : 'tau_z/MTL', 'TAU/NEO_Z' : 'tau_z/Neo', 'TAU/stage_aa_gt' : 'tau_stage_aa/group'\n",
    "})\n",
    "\n",
    "labels = ['low', 'mid', 'high']\n",
    "dummies = pd.get_dummies(nacc_gt['tau_stage_aa/group'])\n",
    "dummies = dummies.reindex(columns=labels, fill_value=0)\n",
    "nacc_gt = pd.concat([nacc_gt, dummies], axis=1).rename(columns={\n",
    "    'low': 'tau_stage_aa/low', 'mid' : 'tau_stage_aa/mid', 'high' : 'tau_stage_aa/high'\n",
    "})\n",
    "cols = ['tau_stage_aa/low', 'tau_stage_aa/mid', 'tau_stage_aa/high']\n",
    "nacc_gt[cols] = nacc_gt[cols].astype(int)\n",
    "\n",
    "\n",
    "print(nacc_stage.shape)\n",
    "print(nacc_gt.shape)\n",
    "\n",
    "r2 = pd.merge(nacc_stage, nacc_gt, on='FULL_ID', how='left')\n",
    "print(r2.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e39330",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stage_inf_nacc = pd.read_csv('C:/Users/WooSikKim/Desktop/Research/projects/co_pathology/scripts/stage_copath/data/nacc/260206_STAGE_PRED_GT_NACC.csv')\n",
    "stage_inf_nacc = r2\n",
    "region_cols = stage_inf_nacc.loc[:, 'VA/2':'VA/2035'].columns\n",
    "stage_inf_nacc = stage_inf_nacc.dropna(subset=region_cols)\n",
    "\n",
    "nacc_aa_cn = stage_inf_nacc[stage_inf_nacc['DX']=='CN']\n",
    "nacc_stage_prep = DataProcessor(\n",
    "    region_cols=region_cols,\n",
    "    dx_col = 'DX',\n",
    "    subject_col='FULL_ID'\n",
    ")\n",
    "\n",
    "nacc_stage_prep.fit_baseline(hc_data=nacc_aa_cn)\n",
    "nacc_Z = nacc_stage_prep.compute_atrophy_scores(data=stage_inf_nacc)\n",
    "nacc_theta = lda.transform(nacc_Z)\n",
    "y_pred = classifier.predict(nacc_theta)\n",
    "y_proba = classifier.predict_proba(nacc_theta)\n",
    "\n",
    "nacc_results = pd.DataFrame(nacc_theta, columns=[f\"Topic_{k}\" for k in range(lda.n_topics)])\n",
    "print(nacc_results.shape)\n",
    "subj_col = nacc_stage_prep.subject_col\n",
    "if subj_col in stage_inf_nacc.columns:\n",
    "    nacc_results.insert(0, \"FULL_ID\", stage_inf_nacc[subj_col].values)\n",
    "    \n",
    "nacc_inp_ready = stage_inf_nacc.merge(nacc_results, on='FULL_ID', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b16e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "nacc_inp_ready.to_csv('C:/Users/WooSikKim/Desktop/Research/projects/co_pathology/scripts/stage_copath/data/stage_data/260206_nacc_stage_external_topic_added_k_8_param.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "992418b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "a4_raw = pd.read_csv('C:/Users/WooSikKim/Desktop/Research/projects/co_pathology/scripts/stage_copath/data/stage_data/A4/A4_external_260203.add_tau_p.va_area_lobe.csv')\n",
    "region_cols = a4_raw.loc[:, 'VA_z/2':'VA_z/2035'].columns\n",
    "a4_raw = a4_raw.dropna(subset=region_cols)\n",
    "\n",
    "a4_Z = a4_raw[region_cols].values\n",
    "a4_Z = -a4_Z\n",
    "a4_Z[a4_Z<0] = 0\n",
    "\n",
    "print(a4_Z.shape)\n",
    "a4_theta = lda.fit_transform(a4_Z)\n",
    "print(a4_theta.shape)\n",
    "y_pred = classifier.predict(a4_theta)\n",
    "y_proba = classifier.predict_proba(a4_theta)\n",
    "\n",
    "a4_results = pd.DataFrame(a4_theta, columns=[f\"Topic_{k}\" for k in range(lda.n_topics)])\n",
    "print(a4_results.shape)\n",
    "if \"FULL_ID\" in a4_raw.columns:\n",
    "    a4_results.insert(0, \"FULL_ID\", a4_raw[subj_col].values)\n",
    "    \n",
    "a4_inp_ready = a4_raw.merge(a4_results, on='FULL_ID', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e14bd84",
   "metadata": {},
   "outputs": [],
   "source": [
    "a4_inp_ready.to_csv('C:/Users/WooSikKim/Desktop/Research/projects/co_pathology/scripts/stage_copath/data/stage_data/260206_a4_stage_external_topic_added_k_8_a_1_b_01.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_management",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
