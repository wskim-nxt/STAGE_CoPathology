{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ceab26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_predict\n",
    "from atlas_vis import DKTAtlas62ROIPlotter\n",
    "\n",
    "\n",
    "new_wsev = pd.read_csv(\"C:/Users/BREIN/Desktop/copathology_visualization_temp/data/260108_wsev_final_df.csv\")\n",
    "hc_df = new_wsev[new_wsev['DX'] == 'HC']\n",
    "\n",
    "df_all = pd.read_csv('C:/Users/BREIN/Desktop/copathology_visualization_temp/data/wsev_old_100_data.csv')\n",
    "df_all = df_all.dropna()\n",
    "print(df_all['DX'].value_counts())\n",
    "\n",
    "region_cols = df_all.loc[:, 'VA/1002':'VA/2035'].columns\n",
    "\n",
    "X_hc = hc_df[hc_df.loc[:,'ctx_lh_caudalanteriorcingulate':'ctx_rh_insula'].columns].values.astype(float)\n",
    "X_pat = df_all[region_cols].values.astype(float)\n",
    "\n",
    "print(f\"HC: {X_hc.shape[0]} subjects\")\n",
    "print(f\"Patients: {X_pat.shape[0]} subjects\")\n",
    "\n",
    "hc_mean = X_hc.mean(axis=0, keepdims=True)\n",
    "hc_std  = X_hc.std(axis=0, keepdims=True) + 1e-8  # avoid divide-by-zero\n",
    "\n",
    "Z = (X_pat - hc_mean) / hc_std\n",
    "\n",
    "X_atrophy = np.maximum(-Z, 0.0)\n",
    "X = X_atrophy\n",
    "X[X < 0] = 0.0\n",
    "\n",
    "n_topics = 6  # try 3–6 in sensitivity analyses\n",
    "\n",
    "lda = LatentDirichletAllocation(\n",
    "    n_components=n_topics,\n",
    "    doc_topic_prior=1.0,      # alpha\n",
    "    topic_word_prior=0.1,     # beta\n",
    "    learning_method='batch',\n",
    "    max_iter=500,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "theta = lda.fit_transform(X)     # subject × topic\n",
    "beta = lda.components_           # topic × region\n",
    "\n",
    "print(\"LDA fitting complete\")\n",
    "\n",
    "# -------------------------------\n",
    "# 4. Normalize topic maps\n",
    "# -------------------------------\n",
    "\n",
    "beta_norm = beta / beta.sum(axis=1, keepdims=True)\n",
    "\n",
    "topic_df = pd.DataFrame(\n",
    "    beta_norm.T,\n",
    "    index=region_cols,\n",
    "    columns=[f\"Topic_{k}\" for k in range(n_topics)]\n",
    ")\n",
    "\n",
    "# -------------------------------\n",
    "# 5. Save topic (atrophy pattern) maps\n",
    "# -------------------------------\n",
    "\n",
    "topic_df.to_csv(\"./old_wsev_results/lda_topic_atrophy_patterns.csv\")\n",
    "print(\"Saved topic atrophy patterns\")\n",
    "\n",
    "# -------------------------------\n",
    "# 6. Subject-level topic mixtures\n",
    "# -------------------------------\n",
    "\n",
    "theta_df = pd.DataFrame(\n",
    "    theta,\n",
    "    columns=[f\"Topic_{k}\" for k in range(n_topics)]\n",
    ")\n",
    "\n",
    "theta_df[\"DX\"] = df_all[\"DX\"].values\n",
    "theta_df.to_csv(\"./old_wsev_results/lda_subject_topic_weights.csv\", index=False)\n",
    "\n",
    "print(\"Saved subject-level topic mixtures\")\n",
    "\n",
    "# -------------------------------\n",
    "# 7. Diagnosis-wise topic expression (post hoc)\n",
    "# -------------------------------\n",
    "\n",
    "group_means = theta_df.groupby(\"DX\").mean()\n",
    "group_means.to_csv(\"./old_wsev_results/lda_diagnosis_topic_expression.csv\")\n",
    "\n",
    "print(\"Saved diagnosis-wise topic expression\")\n",
    "\n",
    "# -------------------------------\n",
    "# 8. Reconstruct diagnosis-specific atrophy maps\n",
    "# -------------------------------\n",
    "\n",
    "dx_maps = {}\n",
    "\n",
    "for dx in group_means.index:\n",
    "    weights = group_means.loc[dx].values\n",
    "    dx_map = np.dot(weights, beta_norm)\n",
    "    dx_maps[dx] = dx_map\n",
    "\n",
    "dx_maps_df = pd.DataFrame(dx_maps, index=region_cols)\n",
    "dx_maps_df.to_csv(\"./old_wsev_results/lda_diagnosis_atrophy_maps.csv\")\n",
    "\n",
    "print(\"Saved diagnosis-specific atrophy maps\")\n",
    "\n",
    "# -------------------------------\n",
    "# 9. Quick sanity checks\n",
    "# -------------------------------\n",
    "\n",
    "print(\"\\nTop regions per topic:\")\n",
    "for k in range(n_topics):\n",
    "    top_regions = (\n",
    "        topic_df[f\"Topic_{k}\"]\n",
    "        .sort_values(ascending=False)\n",
    "        .head(8)\n",
    "    )\n",
    "    print(f\"\\nTopic {k}:\")\n",
    "    print(top_regions)\n",
    "\n",
    "print(\"\\nMean topic expression per diagnosis:\")\n",
    "print(group_means)\n",
    "\n",
    "print(\"\\nDone.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e9795fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from atlas_vis import DKTAtlas62ROIPlotter\n",
    "## Surface Map of VA zscore ##\n",
    "plotter_62  = DKTAtlas62ROIPlotter(\n",
    "    cmap='Reds',\n",
    "    clim=(0, 3.0),  \n",
    "    window_size=(1200, 1000),\n",
    "    nan_color='lightgray',\n",
    "    background='white',\n",
    "    template_key='pial'\n",
    ")\n",
    "new_wsev = pd.read_csv(\"C:/Users/BREIN/Desktop/copathology_visualization_temp/data/260108_wsev_final_df.csv\")\n",
    "hc_df = new_wsev[new_wsev['DX'] == 'HC']\n",
    "\n",
    "df_all = pd.read_csv('C:/Users/BREIN/Desktop/copathology_visualization_temp/data/wsev_old_100_data.csv')\n",
    "df_all = df_all.dropna()\n",
    "print(df_all['DX'].value_counts())\n",
    "\n",
    "region_cols = df_all.loc[:, 'VA/1002':'VA/2035'].columns\n",
    "\n",
    "X_hc = hc_df[hc_df.loc[:,'ctx_lh_caudalanteriorcingulate':'ctx_rh_insula'].columns].values.astype(float)\n",
    "X_pat = df_all[region_cols].values.astype(float)\n",
    "\n",
    "hc_mean = X_hc.mean(axis=0, keepdims=True)\n",
    "hc_std  = X_hc.std(axis=0, keepdims=True) + 1e-8  # avoid divide-by-zero\n",
    "\n",
    "for dx in df_all['DX'].unique():\n",
    "    df_dx = df_all[df_all['DX']==dx]\n",
    "    print(dx)\n",
    "    print(len(df_dx))\n",
    "\n",
    "    X_raw = df_dx[region_cols].values.astype(float)\n",
    "    X_zscore = (X_raw - hc_mean) / hc_std\n",
    "    # X_zscore = np.maximum(-X_zscore, 0.0)\n",
    "    X_zscore = -X_zscore\n",
    "    # Get mean of z-scores across subjects\n",
    "    X_mean_zscore = X_zscore.mean(axis=0)\n",
    "\n",
    "    print(X_mean_zscore.shape)\n",
    "\n",
    "    l_values = X_mean_zscore[:31].tolist()\n",
    "    r_values = X_mean_zscore[31:].tolist()\n",
    "    print(l_values)\n",
    "    print(r_values)\n",
    "    print(len(l_values))\n",
    "    print(len(r_values))\n",
    "    print(np.min(l_values + r_values))\n",
    "    print(np.max(l_values + r_values))\n",
    "\n",
    "    plotter_62(l_values, r_values, save_path=f'./old_wsev_results/surface_maps/zscore/{dx}.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f8c57b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## Surface Map of Raw VA ##\n",
    "plotter_62  = DKTAtlas62ROIPlotter(\n",
    "    cmap='Reds',\n",
    "    clim=(0, 0.2),  \n",
    "    window_size=(1200, 1000),\n",
    "    nan_color='lightgray',\n",
    "    background='white',\n",
    "    template_key='pial'\n",
    ")\n",
    "\n",
    "df = pd.read_csv('C:/Users/BREIN/Desktop/copathology_visualization_temp/lda_with_xg/old_wsev_results/lda_topic_atrophy_patterns.csv')\n",
    "# df.index = df.index.astype(str).str.replace('VA/', '', regex=False)\n",
    "\n",
    "print(len(df))\n",
    "for col in df.columns[1:]:\n",
    "    print(col)\n",
    "    l_values = df.loc[:30,col].to_list()\n",
    "    r_values = df.loc[31:,col].to_list()\n",
    "    print(len(l_values))\n",
    "    print(len(r_values))\n",
    "    print(np.min(l_values+r_values))\n",
    "    print(np.max(l_values+r_values))\n",
    "\n",
    "    plotter_62(l_values, r_values, save_path=f'./old_wsev_results/surface_maps/topicwise/{col}.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0295f16b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.read_csv('C:/Users/BREIN/Desktop/copathology_visualization_temp/lda_with_xg/old_wsev_results/lda_diagnosis_topic_expression.csv')\n",
    "subjects = df.iloc[:, 0].values\n",
    "categories = df.columns[1:].tolist()\n",
    "data = df.iloc[:, 1:].values\n",
    "\n",
    "label_map = {'Topic_0': 'TO', 'Topic_1': 'MT', 'Topic_2': 'TP', 'Topic_3': 'CP', 'Topic_4': 'OFL', 'Topic_5': 'PF'}\n",
    "labels = [label_map[cat] for cat in categories]\n",
    "num_vars = len(categories)\n",
    "angles = np.linspace(0, 2 * np.pi, num_vars, endpoint=False).tolist()\n",
    "angles += angles[:1]\n",
    "\n",
    "# Calculate grid size (add 1 for the combined plot)\n",
    "n_subjects = len(subjects)\n",
    "n_plots = n_subjects + 1  # +1 for combined plot\n",
    "n_cols = 3\n",
    "n_rows = int(np.ceil(n_plots / n_cols))\n",
    "\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(5 * n_cols, 5 * n_rows),subplot_kw=dict(polar=True))\n",
    "axes = axes.flatten()\n",
    "\n",
    "colors = plt.cm.tab10.colors\n",
    "\n",
    "# First subplot: all subjects combined\n",
    "ax = axes[0]\n",
    "for idx, (subject, values) in enumerate(zip(subjects, data)):\n",
    "    values_closed = values.tolist() + [values[0]]\n",
    "    ax.plot(angles, values_closed, 'o-', linewidth=2, \n",
    "            color=colors[idx % len(colors)], label=subject, alpha=0.7)\n",
    "    ax.fill(angles, values_closed, alpha=0.1, color=colors[idx % len(colors)])\n",
    "\n",
    "ax.set_xticks(angles[:-1])\n",
    "ax.set_xticklabels(labels, size=15)\n",
    "ax.set_ylim(0, data.max() * 1.1)\n",
    "ax.set_title('All', size=20)\n",
    "ax.legend(loc='upper right', bbox_to_anchor=(1.1, 1.0), fontsize=6)\n",
    "\n",
    "# Remaining subplots: individual subjects\n",
    "for idx, (subject, values) in enumerate(zip(subjects, data)):\n",
    "    ax = axes[idx + 1]  # Offset by 1\n",
    "    values_closed = values.tolist() + [values[0]]\n",
    "    \n",
    "    ax.plot(angles, values_closed, 'o-', linewidth=2, color=colors[idx % len(colors)])\n",
    "    ax.fill(angles, values_closed, alpha=0.25, color=colors[idx % len(colors)])\n",
    "    ax.set_xticks(angles[:-1])\n",
    "    ax.set_xticklabels(labels, size=15)\n",
    "    ax.set_ylim(0, data.max() * 1.1)\n",
    "    ax.set_title(subject, size=20)\n",
    "\n",
    "# Hide empty subplots\n",
    "for idx in range(n_plots, len(axes)):\n",
    "    axes[idx].set_visible(False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('./old_wsev_results/figures/spider_grid.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc09897f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# XGBoost Multiclass Classification with 5-Fold CV\n",
    "# Using LDA Topic Weights (Out-of-Fold Ensemble Predictions)\n",
    "# ============================================================\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# -------------------------\n",
    "# 1. Load data\n",
    "# -------------------------\n",
    "theta_df = pd.read_csv(\n",
    "    \"C:/Users/BREIN/Desktop/copathology_visualization_temp/lda_with_xg/old_wsev_results/lda_subject_topic_weights.csv\"\n",
    ")\n",
    "\n",
    "topic_cols = [c for c in theta_df.columns if c.startswith(\"Topic_\")]\n",
    "X = theta_df[topic_cols].values\n",
    "y = theta_df[\"DX\"].values\n",
    "subject_idx = theta_df.index.values\n",
    "\n",
    "# Encode DX labels\n",
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(y)\n",
    "dx_classes = le.classes_\n",
    "\n",
    "print(\"DX classes:\", dx_classes)\n",
    "\n",
    "# -------------------------\n",
    "# 2. Stratified 5-fold CV\n",
    "# -------------------------\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "all_y_true = []\n",
    "all_y_pred = []\n",
    "all_y_proba = []\n",
    "all_idx = []\n",
    "\n",
    "for fold, (train_idx, test_idx) in enumerate(skf.split(X, y_encoded), 1):\n",
    "    print(f\"\\n===== Fold {fold} =====\")\n",
    "\n",
    "    X_train, X_test = X[train_idx], X[test_idx]\n",
    "    y_train, y_test = y_encoded[train_idx], y_encoded[test_idx]\n",
    "\n",
    "    xgb = XGBClassifier(\n",
    "        objective=\"multi:softprob\",\n",
    "        num_class=len(dx_classes),\n",
    "        eval_metric=\"mlogloss\",\n",
    "        use_label_encoder=False,\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    xgb.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = xgb.predict(X_test)\n",
    "    y_proba = xgb.predict_proba(X_test)\n",
    "\n",
    "    all_y_true.append(y_test)\n",
    "    all_y_pred.append(y_pred)\n",
    "    all_y_proba.append(y_proba)\n",
    "    all_idx.append(subject_idx[test_idx])\n",
    "\n",
    "# -------------------------\n",
    "# 3. Aggregate CV results\n",
    "# -------------------------\n",
    "y_true_all = np.concatenate(all_y_true)\n",
    "y_pred_all = np.concatenate(all_y_pred)\n",
    "y_proba_all = np.vstack(all_y_proba)\n",
    "idx_all = np.concatenate(all_idx)\n",
    "\n",
    "# -------------------------\n",
    "# 4. Metrics (CV-aggregated)\n",
    "# -------------------------\n",
    "print(\"\\n===== CV-Aggregated Classification Report =====\")\n",
    "print(\n",
    "    classification_report(\n",
    "        y_true_all,\n",
    "        y_pred_all,\n",
    "        target_names=dx_classes\n",
    "    )\n",
    ")\n",
    "\n",
    "cm = confusion_matrix(y_true_all, y_pred_all)\n",
    "accuracy = np.trace(cm) / np.sum(cm)\n",
    "\n",
    "print(\"CV Accuracy:\", round(accuracy, 4))\n",
    "print(\"Confusion Matrix:\\n\", cm)\n",
    "\n",
    "# -------------------------\n",
    "# 5. Build final results DataFrame\n",
    "# -------------------------\n",
    "results_df = pd.DataFrame(\n",
    "    y_proba_all,\n",
    "    columns=[f\"P({dx})\" for dx in dx_classes]\n",
    ")\n",
    "\n",
    "results_df[\"DX_true\"] = le.inverse_transform(y_true_all)\n",
    "results_df[\"DX_pred\"] = le.inverse_transform(y_pred_all)\n",
    "results_df[\"subject_index\"] = idx_all\n",
    "\n",
    "# Sort by true DX for visualization\n",
    "results_df = results_df.sort_values(\"DX_true\").reset_index(drop=True)\n",
    "\n",
    "# -------------------------\n",
    "# 6. Save results\n",
    "# -------------------------\n",
    "out_path = (\n",
    "    \"C:/Users/BREIN/Desktop/copathology_visualization_temp/\"\n",
    "    \"lda_with_xg/old_wsev_results/xgb_5fold_cv_test_predictions.csv\"\n",
    ")\n",
    "results_df.to_csv(out_path, index=False)\n",
    "\n",
    "print(\"\\nSaved CV predictions to:\")\n",
    "print(out_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bb454ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=le.classes_)\n",
    "disp.plot(cmap='Blues', values_format='d')  # or normalize=True for % values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a32d7818",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# ---------------------------------\n",
    "# 1. Merge CV results with topic mixtures\n",
    "# ---------------------------------\n",
    "plot_df = theta_df.loc[results_df[\"subject_index\"]].copy()\n",
    "\n",
    "plot_df[\"DX_true\"] = results_df[\"DX_true\"].values\n",
    "plot_df[\"DX_pred\"] = results_df[\"DX_pred\"].values\n",
    "\n",
    "# ---------------------------------\n",
    "# 2. Compute P(true DX) per subject\n",
    "# ---------------------------------\n",
    "proba_cols = [c for c in results_df.columns if c.startswith(\"P(\")]\n",
    "\n",
    "plot_df[\"p_true_dx\"] = [\n",
    "    results_df.iloc[i][f\"P({dx})\"]\n",
    "    for i, dx in enumerate(plot_df[\"DX_true\"])\n",
    "]\n",
    "\n",
    "# ---------------------------------\n",
    "# 3. Sort subjects:\n",
    "#    group by true DX, then by P(true DX)\n",
    "# ---------------------------------\n",
    "plot_df = plot_df.sort_values(\n",
    "    [\"DX_true\", \"p_true_dx\"],\n",
    "    ascending=[True, False]\n",
    ").reset_index(drop=True)\n",
    "\n",
    "# ---------------------------------\n",
    "# 4. Plot stacked topic mixtures\n",
    "# ---------------------------------\n",
    "label_map = {\n",
    "    'Topic_0': 'LT',\n",
    "    'Topic_1': 'RT',\n",
    "    'Topic_2': 'P',\n",
    "    'Topic_3': 'CO',\n",
    "    'Topic_4': 'ROF',\n",
    "    'Topic_5': 'LPF'\n",
    "}\n",
    "\n",
    "topic_cols = [c for c in plot_df.columns if c.startswith(\"Topic_\")]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(14, 5))\n",
    "\n",
    "bottom = np.zeros(len(plot_df))\n",
    "colors = sns.color_palette(\"tab20\", len(topic_cols))\n",
    "\n",
    "for i, topic in enumerate(topic_cols):\n",
    "    ax.bar(\n",
    "        np.arange(len(plot_df)),\n",
    "        plot_df[topic],\n",
    "        bottom=bottom,\n",
    "        color=colors[i],\n",
    "        label=label_map.get(topic, topic)\n",
    "    )\n",
    "    bottom += plot_df[topic].values\n",
    "\n",
    "# ---------------------------------\n",
    "# 5. Axis styling\n",
    "# ---------------------------------\n",
    "ax.set_xticks([])\n",
    "ax.set_ylabel(\"Topic proportion\")\n",
    "ax.set_ylim(0, 1.08)  # <-- CRITICAL FIX\n",
    "ax.set_title(\n",
    "    \"Topic Mixtures per Subject (5-fold CV)\\n\"\n",
    "    \"(Grouped by DX, Sorted by P(Actual DX))\"\n",
    ")\n",
    "\n",
    "# ---------------------------------\n",
    "# 6. DX group labels & separators\n",
    "# ---------------------------------\n",
    "current = 0\n",
    "for dx in plot_df[\"DX_true\"].unique():\n",
    "    count = (plot_df[\"DX_true\"] == dx).sum()\n",
    "\n",
    "    ax.text(\n",
    "        current + count / 2 - 0.5,\n",
    "        -0.05,\n",
    "        dx,\n",
    "        ha=\"center\",\n",
    "        va=\"top\",\n",
    "        fontsize=12\n",
    "    )\n",
    "\n",
    "    ax.axvline(current - 0.5, color=\"black\", linewidth=1.5)\n",
    "    current += count\n",
    "\n",
    "ax.axvline(current - 0.5, color=\"black\", linewidth=1.5)\n",
    "\n",
    "# ---------------------------------\n",
    "# 7. Mark misclassified subjects\n",
    "# ---------------------------------\n",
    "misclassified = plot_df[\"DX_true\"] != plot_df[\"DX_pred\"]\n",
    "\n",
    "ax.scatter(\n",
    "    np.where(misclassified)[0],\n",
    "    np.ones(misclassified.sum()) * 1.03,\n",
    "    color=\"red\",\n",
    "    marker=\"x\",\n",
    "    s=60,\n",
    "    linewidths=2,\n",
    "    label=\"Misclassified\",\n",
    "    zorder=10\n",
    ")\n",
    "\n",
    "# ---------------------------------\n",
    "# 8. Legend & layout\n",
    "# ---------------------------------\n",
    "ax.legend(\n",
    "    title=\"LDA Topics\",\n",
    "    bbox_to_anchor=(1.05, 1),\n",
    "    loc=\"upper left\"\n",
    ")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34772192",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# ---------------------------------\n",
    "# 1. Prepare probability columns\n",
    "# ---------------------------------\n",
    "proba_cols = [c for c in results_df.columns if c.startswith(\"P(\")]\n",
    "dx_labels = [c.replace(\"P(\", \"\").replace(\")\", \"\") for c in proba_cols]\n",
    "\n",
    "# Align probabilities to plot_df order\n",
    "df = results_df.loc[plot_df.index, proba_cols].copy()\n",
    "df[\"DX_true\"] = plot_df[\"DX_true\"].values\n",
    "df[\"DX_pred\"] = plot_df[\"DX_pred\"].values\n",
    "\n",
    "# ---------------------------------\n",
    "# 2. Sort subjects:\n",
    "#    group by true DX,\n",
    "#    within group sort by P(true DX)\n",
    "# ---------------------------------\n",
    "sorted_blocks = []\n",
    "\n",
    "for dx in df[\"DX_true\"].unique():\n",
    "    dx_block = df[df[\"DX_true\"] == dx].copy()\n",
    "\n",
    "    true_dx_col = f\"P({dx})\"\n",
    "    if true_dx_col not in dx_block.columns:\n",
    "        raise ValueError(f\"Missing probability column: {true_dx_col}\")\n",
    "\n",
    "    dx_block = dx_block.sort_values(\n",
    "        by=true_dx_col,\n",
    "        ascending=False\n",
    "    )\n",
    "\n",
    "    sorted_blocks.append(dx_block)\n",
    "\n",
    "proba_plot_df = (\n",
    "    pd.concat(sorted_blocks)\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "# ---------------------------------\n",
    "# 3. Stacked bar plot\n",
    "# ---------------------------------\n",
    "fig, ax = plt.subplots(figsize=(14, 5))\n",
    "\n",
    "bottom = np.zeros(len(proba_plot_df))\n",
    "colors = sns.color_palette(\"tab10\", len(dx_labels))\n",
    "\n",
    "for i, (dx, col) in enumerate(zip(dx_labels, proba_cols)):\n",
    "    ax.bar(\n",
    "        np.arange(len(proba_plot_df)),\n",
    "        proba_plot_df[col],\n",
    "        bottom=bottom,\n",
    "        color=colors[i],\n",
    "        label=dx\n",
    "    )\n",
    "    bottom += proba_plot_df[col].values\n",
    "\n",
    "ax.set_xticks([])\n",
    "ax.set_ylabel(\"Predicted DX probability\")\n",
    "ax.set_ylim(0, 1)\n",
    "ax.set_title(\n",
    "    \"Predicted Diagnosis Probabilities per Subject (5-fold CV)\\n\"\n",
    "    \"(Grouped by True DX, Sorted by P(True DX))\"\n",
    ")\n",
    "\n",
    "# ---------------------------------\n",
    "# 4. Add DX group labels & separators\n",
    "# ---------------------------------\n",
    "current = 0\n",
    "\n",
    "for dx in proba_plot_df[\"DX_true\"].unique():\n",
    "    count = (proba_plot_df[\"DX_true\"] == dx).sum()\n",
    "\n",
    "    ax.text(\n",
    "        current + count / 2 - 0.5,\n",
    "        -0.05,\n",
    "        dx,\n",
    "        ha=\"center\",\n",
    "        va=\"top\",\n",
    "        fontsize=12\n",
    "    )\n",
    "\n",
    "    ax.axvline(current - 0.5, color=\"black\", linewidth=1.5)\n",
    "    current += count\n",
    "\n",
    "ax.axvline(current - 0.5, color=\"black\", linewidth=1.5)\n",
    "\n",
    "ax.legend(\n",
    "    title=\"Predicted DX\",\n",
    "    bbox_to_anchor=(1.05, 1),\n",
    "    loc=\"upper left\"\n",
    ")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d458401f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# ---------------------------------\n",
    "# 1. Prepare probability columns\n",
    "# ---------------------------------\n",
    "proba_cols = [c for c in proba_plot_df.columns if c.startswith(\"P(\")]\n",
    "dx_labels = [c.replace(\"P(\", \"\").replace(\")\", \"\") for c in proba_cols]\n",
    "\n",
    "df = proba_plot_df.copy()\n",
    "\n",
    "# ---------------------------------\n",
    "# 2. Sort subjects:\n",
    "#    - group by true DX\n",
    "#    - within group, sort by P(true DX) descending\n",
    "# ---------------------------------\n",
    "sorted_blocks = []\n",
    "\n",
    "for dx in df[\"DX_true\"].unique():\n",
    "    dx_block = df[df[\"DX_true\"] == dx].copy()\n",
    "\n",
    "    true_dx_col = f\"P({dx})\"\n",
    "    if true_dx_col not in dx_block.columns:\n",
    "        raise ValueError(f\"Missing probability column: {true_dx_col}\")\n",
    "\n",
    "    dx_block = dx_block.sort_values(\n",
    "        by=true_dx_col,\n",
    "        ascending=False\n",
    "    )\n",
    "\n",
    "    sorted_blocks.append(dx_block)\n",
    "\n",
    "df_sorted = pd.concat(sorted_blocks).reset_index(drop=True)\n",
    "\n",
    "# ---------------------------------\n",
    "# 3. Heatmap data\n",
    "# ---------------------------------\n",
    "heatmap_data = df_sorted[proba_cols].values\n",
    "\n",
    "# ---------------------------------\n",
    "# 4. Plot heatmap\n",
    "# ---------------------------------\n",
    "plt.figure(figsize=(8, 10))\n",
    "\n",
    "ax = sns.heatmap(\n",
    "    heatmap_data,\n",
    "    cmap=\"Reds\",\n",
    "    vmin=0,\n",
    "    vmax=1,\n",
    "    cbar_kws={\"label\": \"Predicted DX probability\"},\n",
    "    yticklabels=False,\n",
    "    xticklabels=dx_labels\n",
    ")\n",
    "\n",
    "ax.set_xlabel(\"Predicted Diagnosis\")\n",
    "ax.set_ylabel(\"Subjects (True DX)\")\n",
    "ax.set_title(\n",
    "    \"Predicted Diagnosis Probabilities per Subject\\n\"\n",
    "    \"(Grouped by True DX, Sorted by P(True DX))\"\n",
    ")\n",
    "\n",
    "# ---------------------------------\n",
    "# 5. Add true DX group labels + lines\n",
    "# ---------------------------------\n",
    "current = 0\n",
    "yticks = []\n",
    "ylabels = []\n",
    "\n",
    "for dx in df_sorted[\"DX_true\"].unique():\n",
    "    count = (df_sorted[\"DX_true\"] == dx).sum()\n",
    "    midpoint = current + count / 2\n",
    "\n",
    "    yticks.append(midpoint)\n",
    "    ylabels.append(dx)\n",
    "\n",
    "    ax.hlines(\n",
    "        current,\n",
    "        xmin=0,\n",
    "        xmax=len(dx_labels),\n",
    "        colors=\"black\",\n",
    "        linewidth=1.5\n",
    "    )\n",
    "\n",
    "    current += count\n",
    "\n",
    "# Final boundary\n",
    "ax.hlines(\n",
    "    current,\n",
    "    xmin=0,\n",
    "    xmax=len(dx_labels),\n",
    "    colors=\"black\",\n",
    "    linewidth=1.5\n",
    ")\n",
    "\n",
    "ax.set_yticks(yticks)\n",
    "ax.set_yticklabels(ylabels, rotation=0)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_management",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
